{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Parallelism with Machine Learning: The Housing Prices Competition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the competition\n",
    "\n",
    "- The Housing Prices Competition train_dataset consists of various features of residential homes in Ames, Iowa, including both quantitative and categorical variables like the size of the property, the number of rooms, year built, and neighborhood quality.\n",
    "- It includes a set of 79 explanatory variables describing almost every aspect of the houses, allowing for in-depth analysis.\n",
    "- *The primary goal* of the competition is to predict **the final price of each home**, in this lab we will use *RandomForests*.\n",
    "- The models are evaluated on Root Mean Squared Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price, encouraging precise predictions over a range of housing prices.\n",
    "\n",
    "### File descriptions\n",
    "- *train.csv*: the training set used to train the model.\n",
    "- *test.csv*: the test set used to compute the performance of the model.\n",
    "- *train_data_description.txt*: full description of each column.\n",
    "### Useful train_data fields\n",
    "\n",
    "Here's a brief version of what you'll find in the train_data description file.\n",
    "\n",
    "- *SalePrice*: the property's sale price in dollars. This is the target variable that you're trying to predict.\n",
    "- *MSSubClass*: The building class\n",
    "- *MSZoning*: The general zoning classification\n",
    "\n",
    "Teh train_dataset is acessible here: https://www.kaggle.com/code/dansbecker/random-forests/tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and prepare the train_data\n",
    "*If you're curious about this the professor can explain it for you*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the train_dataset\n",
    "file_path = '../data/housing_prices_data/train.csv'\n",
    "train_data = pd.read_csv(file_path, index_col=\"Id\")\n",
    "\n",
    "# Columns to be deleted\n",
    "columns_to_delete = ['MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']\n",
    "\n",
    "# Delete the specified columns\n",
    "train_data_cleaned = train_data.drop(columns=columns_to_delete, axis=1)\n",
    "\n",
    "# Define the input features (X) and the output (y)\n",
    "X = train_data_cleaned.drop('SalePrice', axis=1)\n",
    "y = train_data_cleaned['SalePrice']\n",
    "\n",
    "# Identify the categorical columns in X\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Initialize a LabelEncoder for each categorical column\n",
    "label_encoders = {column: LabelEncoder() for column in categorical_columns}\n",
    "\n",
    "# Apply Label Encoding to each categorical column\n",
    "for column in categorical_columns:\n",
    "    X[column] = label_encoders[column].fit_transform(X[column])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 70), (438, 70), (1022,), (438,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the first dataset (X, y) into train and test sets with a 70% - 30% split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Fill NaN values in X_train and X_val with the median of the respective columns\n",
    "X_train_filled = X_train.fillna(X_train.median())\n",
    "X_val_filled = X_val.fillna(X_val.median())\n",
    "\n",
    "(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First RandomForest Model\n",
    "This is the code for a simple trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 26057.941851126383, MAPE: 9.868196740754167%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "# Create a Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_model.fit(X_train_filled, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_val_pred_filled = rf_model.predict(X_val_filled)\n",
    "\n",
    "# Calculate the RMSE on the validation data\n",
    "rmse_filled = sqrt(mean_squared_error(y_val, y_val_pred_filled))\n",
    "\n",
    "# Calculate MAPE (mean absolute percentage error)\n",
    "mape = mean_absolute_percentage_error(y_val, y_val_pred_filled) * 100\n",
    "\n",
    "# Print the RMSE and MAPE\n",
    "print(f\"RMSE: {rmse_filled}, MAPE: {mape}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of Random Forest Model\n",
    "The three most important parameters that typically have the most impact on the performance of a Random Forest model are:\n",
    "\n",
    "- *n_estimators*: This parameter specifies the number of trees in the forest. Generally, a higher number of trees increases the performance and makes the predictions more stable, but it also makes the computation slower. Selecting the right number of trees requires balancing between performance and computational efficiency.\n",
    "\n",
    "- *max_features*: This parameter defines the maximum number of features that are allowed to try in an individual tree. There are several options available for this parameter:\n",
    "\n",
    "    - *sqrt*: This is commonly used and means that the maximum number of features used at each split is the square root of the total number of features.\n",
    "    - *log2*: This is another typical option, meaning the log base 2 of the feature count is used.\n",
    "    - *A specific integer or float*: You can specify an exact number or a proportion of the total.\n",
    "\n",
    "- *max_depth*: This parameter specifies the maximum depth of each tree. Deeper trees can model more complex patterns, but they also risk overfitting. Limiting the depth of trees can improve the model's generalization and reduce overfitting. It's often useful to set this parameter to a finite value, especially when dealing with a large number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best parameters sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters: 10, sqrt, 1. RMSE: 62936.129262244904, MAPE: 26.860734529882123%\n",
      "The parameters: 10, sqrt, 2. RMSE: 51806.105176310826, MAPE: 20.52147680573829%\n",
      "The parameters: 10, sqrt, 5. RMSE: 34018.6946431472, MAPE: 13.846204059816515%\n",
      "The parameters: 10, sqrt, 10. RMSE: 30158.362616471855, MAPE: 11.1847373574493%\n",
      "The parameters: 10, sqrt, 20. RMSE: 30593.76147467334, MAPE: 11.148658516638926%\n",
      "The parameters: 10, sqrt, None. RMSE: 28608.440009540453, MAPE: 11.124252485645316%\n",
      "The parameters: 10, log2, 1. RMSE: 64442.107292878405, MAPE: 27.58882909655716%\n",
      "The parameters: 10, log2, 2. RMSE: 51396.530250771764, MAPE: 21.498982900746558%\n",
      "The parameters: 10, log2, 5. RMSE: 34956.394381827566, MAPE: 13.945831547616713%\n",
      "The parameters: 10, log2, 10. RMSE: 30136.927641357106, MAPE: 11.160840785213171%\n",
      "The parameters: 10, log2, 20. RMSE: 30841.310557247474, MAPE: 11.240205002153882%\n",
      "The parameters: 10, log2, None. RMSE: 29000.351214559596, MAPE: 10.98098439114081%\n",
      "The parameters: 10, None, 1. RMSE: 57823.30960766656, MAPE: 25.854236053260713%\n",
      "The parameters: 10, None, 2. RMSE: 44738.9675013081, MAPE: 19.39967435427367%\n",
      "The parameters: 10, None, 5. RMSE: 30977.339419939668, MAPE: 12.32718845204275%\n",
      "The parameters: 10, None, 10. RMSE: 26371.732325187742, MAPE: 10.387601696539232%\n",
      "The parameters: 10, None, 20. RMSE: 27582.089072839033, MAPE: 10.336644923118392%\n",
      "The parameters: 10, None, None. RMSE: 28062.104755431203, MAPE: 10.28772353916743%\n",
      "The parameters: 25, sqrt, 1. RMSE: 60720.06723428002, MAPE: 25.2463033064465%\n",
      "The parameters: 25, sqrt, 2. RMSE: 48999.969822412146, MAPE: 19.141115612087532%\n",
      "The parameters: 25, sqrt, 5. RMSE: 32317.961786662752, MAPE: 13.114437916762203%\n",
      "The parameters: 25, sqrt, 10. RMSE: 28259.543521821943, MAPE: 10.47369873275887%\n",
      "The parameters: 25, sqrt, 20. RMSE: 28601.996953881055, MAPE: 10.651671775420226%\n",
      "The parameters: 25, sqrt, None. RMSE: 28437.477716170713, MAPE: 10.650717147533856%\n",
      "The parameters: 25, log2, 1. RMSE: 62175.23336548907, MAPE: 26.103334605968907%\n",
      "The parameters: 25, log2, 2. RMSE: 49454.96222058965, MAPE: 20.009887677109557%\n",
      "The parameters: 25, log2, 5. RMSE: 34640.741335575985, MAPE: 13.585957690083541%\n",
      "The parameters: 25, log2, 10. RMSE: 29797.647023472127, MAPE: 10.802129162615948%\n",
      "The parameters: 25, log2, 20. RMSE: 28152.423144151206, MAPE: 10.113221227840645%\n",
      "The parameters: 25, log2, None. RMSE: 28624.714349076796, MAPE: 10.195238945186857%\n",
      "The parameters: 25, None, 1. RMSE: 57545.23094798376, MAPE: 25.562043938945223%\n",
      "The parameters: 25, None, 2. RMSE: 44503.99568777034, MAPE: 18.93356623365525%\n",
      "The parameters: 25, None, 5. RMSE: 30622.018751108048, MAPE: 12.284801453967585%\n",
      "The parameters: 25, None, 10. RMSE: 27253.405412634103, MAPE: 10.272632581222856%\n",
      "The parameters: 25, None, 20. RMSE: 26499.315199813544, MAPE: 10.019023380641842%\n",
      "The parameters: 25, None, None. RMSE: 27011.528848190042, MAPE: 10.057567711051357%\n",
      "The parameters: 50, sqrt, 1. RMSE: 60346.5737195233, MAPE: 25.162121091064353%\n",
      "The parameters: 50, sqrt, 2. RMSE: 48952.98192411672, MAPE: 19.219570888426375%\n",
      "The parameters: 50, sqrt, 5. RMSE: 32807.733869677046, MAPE: 12.765423020132053%\n",
      "The parameters: 50, sqrt, 10. RMSE: 28193.908384996157, MAPE: 10.30283712157863%\n",
      "The parameters: 50, sqrt, 20. RMSE: 28322.13190140527, MAPE: 10.266831234466041%\n",
      "The parameters: 50, sqrt, None. RMSE: 28253.30753002766, MAPE: 10.301610941463089%\n",
      "The parameters: 50, log2, 1. RMSE: 61769.11746990103, MAPE: 26.024888854218215%\n",
      "The parameters: 50, log2, 2. RMSE: 49973.37697266408, MAPE: 19.855069340876533%\n",
      "The parameters: 50, log2, 5. RMSE: 35272.23782970266, MAPE: 13.259237055635129%\n",
      "The parameters: 50, log2, 10. RMSE: 29337.548793235695, MAPE: 10.69972715022594%\n",
      "The parameters: 50, log2, 20. RMSE: 28219.379219234233, MAPE: 10.054841695082303%\n",
      "The parameters: 50, log2, None. RMSE: 28552.120501147994, MAPE: 10.110335561128336%\n",
      "The parameters: 50, None, 1. RMSE: 57505.08832414332, MAPE: 25.40677081979206%\n",
      "The parameters: 50, None, 2. RMSE: 44571.23631103615, MAPE: 18.993732376822592%\n",
      "The parameters: 50, None, 5. RMSE: 30578.268789069476, MAPE: 12.246352597445519%\n",
      "The parameters: 50, None, 10. RMSE: 26549.03681495154, MAPE: 10.164540522209597%\n",
      "The parameters: 50, None, 20. RMSE: 26616.753965688236, MAPE: 9.95616179407857%\n",
      "The parameters: 50, None, None. RMSE: 26659.206888314602, MAPE: 9.950072723845874%\n",
      "The parameters: 100, sqrt, 1. RMSE: 60511.413390408285, MAPE: 24.970655834062548%\n",
      "The parameters: 100, sqrt, 2. RMSE: 48423.20979308409, MAPE: 19.124218836706603%\n",
      "The parameters: 100, sqrt, 5. RMSE: 32585.44117019146, MAPE: 12.510275320688514%\n",
      "The parameters: 100, sqrt, 10. RMSE: 27940.66308571875, MAPE: 10.232467246501514%\n",
      "The parameters: 100, sqrt, 20. RMSE: 27530.724415300712, MAPE: 10.125866760621907%\n",
      "The parameters: 100, sqrt, None. RMSE: 27690.85111196373, MAPE: 10.111048513592108%\n",
      "The parameters: 100, log2, 1. RMSE: 62166.92632864128, MAPE: 25.90574767935297%\n",
      "The parameters: 100, log2, 2. RMSE: 49946.811096505524, MAPE: 19.85047840173841%\n",
      "The parameters: 100, log2, 5. RMSE: 34438.66151846642, MAPE: 13.17388786526951%\n",
      "The parameters: 100, log2, 10. RMSE: 28459.288873741767, MAPE: 10.547559689956204%\n",
      "The parameters: 100, log2, 20. RMSE: 27471.51821338425, MAPE: 9.805906069975684%\n",
      "The parameters: 100, log2, None. RMSE: 27735.747830866087, MAPE: 10.003262143296658%\n",
      "The parameters: 100, None, 1. RMSE: 57211.16615127391, MAPE: 25.025965875120264%\n",
      "The parameters: 100, None, 2. RMSE: 44472.47296968139, MAPE: 18.836095197090465%\n",
      "The parameters: 100, None, 5. RMSE: 30154.47423520161, MAPE: 12.085654020145233%\n",
      "The parameters: 100, None, 10. RMSE: 26265.099994067186, MAPE: 10.040721857978957%\n",
      "The parameters: 100, None, 20. RMSE: 26152.741599610163, MAPE: 9.913529753089874%\n",
      "The parameters: 100, None, None. RMSE: 26057.941851126383, MAPE: 9.868196740754167%\n",
      "The parameters: 200, sqrt, 1. RMSE: 60592.20080413971, MAPE: 25.348413331204604%\n",
      "The parameters: 200, sqrt, 2. RMSE: 48456.200987649645, MAPE: 19.31834333556386%\n",
      "The parameters: 200, sqrt, 5. RMSE: 32921.85786148226, MAPE: 12.593595077314337%\n",
      "The parameters: 200, sqrt, 10. RMSE: 28088.902620554447, MAPE: 10.205458456989026%\n",
      "The parameters: 200, sqrt, 20. RMSE: 27532.91156851607, MAPE: 9.99674498484024%\n",
      "The parameters: 200, sqrt, None. RMSE: 27430.923405573616, MAPE: 10.001128964051244%\n",
      "The parameters: 200, log2, 1. RMSE: 62120.39237086007, MAPE: 26.338849401949805%\n",
      "The parameters: 200, log2, 2. RMSE: 50047.12857344109, MAPE: 20.132262501400174%\n",
      "The parameters: 200, log2, 5. RMSE: 34734.445288631454, MAPE: 13.310668983679474%\n",
      "The parameters: 200, log2, 10. RMSE: 28692.19328330196, MAPE: 10.425408664401772%\n",
      "The parameters: 200, log2, 20. RMSE: 27918.172300177175, MAPE: 9.871948875899832%\n",
      "The parameters: 200, log2, None. RMSE: 28122.610919892722, MAPE: 10.075865891296619%\n",
      "The parameters: 200, None, 1. RMSE: 57330.65911329287, MAPE: 25.203756111774418%\n",
      "The parameters: 200, None, 2. RMSE: 44545.47770035227, MAPE: 18.8459387073764%\n",
      "The parameters: 200, None, 5. RMSE: 30056.99415042013, MAPE: 12.027413013145498%\n",
      "The parameters: 200, None, 10. RMSE: 26485.54967760915, MAPE: 9.968649121179467%\n",
      "The parameters: 200, None, 20. RMSE: 26191.615393143096, MAPE: 9.814804116215956%\n",
      "The parameters: 200, None, None. RMSE: 26109.529848542985, MAPE: 9.785264413857124%\n",
      "The parameters: 300, sqrt, 1. RMSE: 60929.66932059552, MAPE: 25.5233017132497%\n",
      "The parameters: 300, sqrt, 2. RMSE: 48477.515732693806, MAPE: 19.45952457308847%\n",
      "The parameters: 300, sqrt, 5. RMSE: 32739.920144412845, MAPE: 12.654260849343446%\n",
      "The parameters: 300, sqrt, 10. RMSE: 27720.206311955073, MAPE: 10.158753220059861%\n",
      "The parameters: 300, sqrt, 20. RMSE: 27459.785134152986, MAPE: 9.886952721263405%\n",
      "The parameters: 300, sqrt, None. RMSE: 27394.84596466395, MAPE: 9.923924926914179%\n",
      "The parameters: 300, log2, 1. RMSE: 62683.20415726862, MAPE: 26.538128720991566%\n",
      "The parameters: 300, log2, 2. RMSE: 50458.67950947336, MAPE: 20.275483738507045%\n",
      "The parameters: 300, log2, 5. RMSE: 34565.6574161325, MAPE: 13.300516763849002%\n",
      "The parameters: 300, log2, 10. RMSE: 28541.379624482677, MAPE: 10.42483342213683%\n",
      "The parameters: 300, log2, 20. RMSE: 27744.585234343336, MAPE: 9.924986717080374%\n",
      "The parameters: 300, log2, None. RMSE: 27972.716859688764, MAPE: 10.050994009021618%\n",
      "The parameters: 300, None, 1. RMSE: 57645.45868384868, MAPE: 25.615849754017994%\n",
      "The parameters: 300, None, 2. RMSE: 44468.13497206259, MAPE: 18.973613128632305%\n",
      "The parameters: 300, None, 5. RMSE: 30053.282347030145, MAPE: 12.040192412613166%\n",
      "The parameters: 300, None, 10. RMSE: 26435.067646149004, MAPE: 9.957708448691804%\n",
      "The parameters: 300, None, 20. RMSE: 26224.452972222785, MAPE: 9.831241564947488%\n",
      "The parameters: 300, None, None. RMSE: 26176.10432944751, MAPE: 9.801826393115594%\n",
      "The parameters: 400, sqrt, 1. RMSE: 60914.53857642404, MAPE: 25.51869058914844%\n",
      "The parameters: 400, sqrt, 2. RMSE: 48669.695843852176, MAPE: 19.530745286106946%\n",
      "The parameters: 400, sqrt, 5. RMSE: 32809.62783027221, MAPE: 12.71009467191943%\n",
      "The parameters: 400, sqrt, 10. RMSE: 27744.18030444477, MAPE: 10.125160913453673%\n",
      "The parameters: 400, sqrt, 20. RMSE: 27497.671359831445, MAPE: 9.905124417060355%\n",
      "The parameters: 400, sqrt, None. RMSE: 27418.113736521427, MAPE: 9.945984648595795%\n",
      "The parameters: 400, log2, 1. RMSE: 62661.54638863782, MAPE: 26.43424504101804%\n",
      "The parameters: 400, log2, 2. RMSE: 50422.97022602301, MAPE: 20.23343384859187%\n",
      "The parameters: 400, log2, 5. RMSE: 34496.868353168815, MAPE: 13.290480205939964%\n",
      "The parameters: 400, log2, 10. RMSE: 28518.64779526882, MAPE: 10.390264584164836%\n",
      "The parameters: 400, log2, 20. RMSE: 27800.35162861101, MAPE: 9.91776916154931%\n",
      "The parameters: 400, log2, None. RMSE: 27905.32754903062, MAPE: 10.017981777351737%\n",
      "The parameters: 400, None, 1. RMSE: 57795.7474853705, MAPE: 25.753019610226186%\n",
      "The parameters: 400, None, 2. RMSE: 44508.690046548625, MAPE: 19.00415009775348%\n",
      "The parameters: 400, None, 5. RMSE: 30246.733688359316, MAPE: 12.052665031964972%\n",
      "The parameters: 400, None, 10. RMSE: 26626.130211240506, MAPE: 9.967897691949654%\n",
      "The parameters: 400, None, 20. RMSE: 26466.61626732859, MAPE: 9.851633812842412%\n",
      "The parameters: 400, None, None. RMSE: 26362.199455330487, MAPE: 9.83203095544113%\n",
      "The best parameters {'n_estimators': 100, 'max_features': None, 'max_depth': None} for RMSE = 26057.941851126383, MAPE: 9.83203095544113%\n",
      "The sequential execution time is 64.19577407836914\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Define the parameter ranges\n",
    "n_estimators_range = [10, 25, 50, 100, 200, 300, 400]\n",
    "max_features_range = ['sqrt', 'log2', None]  # None means using all features\n",
    "max_depth_range = [1, 2, 5, 10, 20, None]  # None means no limit\n",
    "\n",
    "# Initialize variables to store the best model and its RMSE and parameters\n",
    "best_rmse = float('inf')\n",
    "best_mape = float('inf')\n",
    "best_model = None\n",
    "best_parameters = {}\n",
    "\n",
    "# Loop over all possible combinations of parameters\n",
    "for n_estimators in n_estimators_range:\n",
    "    for max_features in max_features_range:\n",
    "        for max_depth in max_depth_range:\n",
    "            # Create and train the Random Forest model\n",
    "            rf_model = RandomForestRegressor(\n",
    "                n_estimators=n_estimators,\n",
    "                max_features=max_features,\n",
    "                max_depth=max_depth,\n",
    "                random_state=42\n",
    "            )\n",
    "            rf_model.fit(X_train_filled, y_train)\n",
    "            \n",
    "            # Make predictions and compute RMSE\n",
    "            y_val_pred = rf_model.predict(X_val_filled)\n",
    "            rmse = sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "            # Compute MAPE\n",
    "            mape = mean_absolute_percentage_error(y_val, y_val_pred) * 100\n",
    "            print(f\"The parameters: {n_estimators}, {max_features}, {max_depth}. RMSE: {rmse}, MAPE: {mape}%\")\n",
    "            # If the model is better than the current best, update the best model and its parameters\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_mape = mape\n",
    "                best_model = rf_model\n",
    "                best_parameters = {\n",
    "                    'n_estimators': n_estimators,\n",
    "                    'max_features': max_features,\n",
    "                    'max_depth': max_depth\n",
    "                }\n",
    "print(f\"The best parameters {best_parameters} for RMSE = {best_rmse}, MAPE: {mape}%\")\n",
    "end_time = time.time()\n",
    "sequential_time = start_time - end_time\n",
    "print(f\"The sequential execution time is {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying parallelism "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def data_preprocessing():\n",
    "    # Load the train_dataset\n",
    "    file_path = '../data/housing_prices_data/train.csv'\n",
    "    train_data = pd.read_csv(file_path, index_col=\"Id\")\n",
    "\n",
    "    # Columns to be deleted\n",
    "    columns_to_delete = ['MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']\n",
    "\n",
    "    # Delete the specified columns\n",
    "    train_data_cleaned = train_data.drop(columns=columns_to_delete, axis=1)\n",
    "\n",
    "    # Define the input features (X) and the output (y)\n",
    "    X = train_data_cleaned.drop('SalePrice', axis=1)\n",
    "    y = train_data_cleaned['SalePrice']\n",
    "\n",
    "    # Identify the categorical columns in X\n",
    "    categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "    # Initialize a LabelEncoder for each categorical column\n",
    "    label_encoders = {column: LabelEncoder() for column in categorical_columns}\n",
    "\n",
    "    # Apply Label Encoding to each categorical column\n",
    "    for column in categorical_columns:\n",
    "        X[column] = label_encoders[column].fit_transform(X[column])\n",
    "\n",
    "    # Split the first dataset (X, y) into train and test sets with a 70% - 30% split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "    # Fill NaN values in X_train and X_val with the median of the respective columns\n",
    "    X_train_filled = X_train.fillna(X_train.median())\n",
    "    X_val_filled = X_val.fillna(X_val.median())\n",
    "    \n",
    "    return (X_train_filled, X_val_filled, y_train, y_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "def train_model(n_estimators, max_features, max_depth, shared_data):\n",
    "    global X_train_filled, y_train, X_val_filled, y_val\n",
    "    # Create and train the Random Forest model\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_features=max_features,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X_train_filled, y_train)\n",
    "    \n",
    "    # Make predictions and compute RMSE\n",
    "    y_val_pred = rf_model.predict(X_val_filled)\n",
    "    rmse = sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    # Compute MAPE\n",
    "    mape = mean_absolute_percentage_error(y_val, y_val_pred) * 100\n",
    "    print(f\"The parameters: {n_estimators}, {max_features}, {max_depth}. RMSE: {rmse}, MAPE: {mape}%\")\n",
    "    # If the model is better than the current best, update the best model and its parameters\n",
    "    if rmse < shared_data['best_rmse']:\n",
    "        shared_data['best_rmse'] = rmse\n",
    "        shared_data['best_mape'] = mape\n",
    "        shared_data['best_model'] = rf_model\n",
    "        shared_data['best_parameters'] = {\n",
    "            'n_estimators': n_estimators,\n",
    "            'max_features': max_features,\n",
    "            'max_depth': max_depth\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def sequential_parameter_finder(n_estimators_range, max_features_range, max_depth_range):\n",
    "    print(\"*\"*20, \"Starting Sequential Parameter Finder\", \"*\"*20)\n",
    "    parallel_time = time.time()\n",
    "    \n",
    "    # Initialize variables to store the best model and its RMSE and parameters\n",
    "    shared_data = dict()\n",
    "    shared_data['best_rmse'] = float('inf')\n",
    "    shared_data['best_mape'] = float('inf')\n",
    "    shared_data['best_model'] = None\n",
    "    shared_data['best_parameters'] = {}\n",
    "\n",
    "    # Loop over all possible combinations of parameters\n",
    "    for n_estimators in n_estimators_range:\n",
    "        for max_features in max_features_range:\n",
    "            for max_depth in max_depth_range:\n",
    "                train_model(n_estimators, max_features, max_depth, shared_data)\n",
    "\n",
    "    print(f\"The best parameters {shared_data['best_parameters']} for RMSE = {shared_data['best_rmse']}, MAPE: {shared_data['best_mape']}%\")\n",
    "    \n",
    "    parallel_time = time.time() - parallel_time \n",
    "    print(f\"The sequential execution time is {parallel_time}\", \"\\n\"*5)\n",
    "    return parallel_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "\n",
    "def threading_parameter_finder(n_estimators_range, max_features_range, max_depth_range):\n",
    "    print(\"*\"*20, \"Starting Threading Parameter Finder\", \"*\"*20)\n",
    "    parallel_time = time.time()\n",
    "    # Initialize variables to store the best model and its RMSE and parameters\n",
    "    shared_data = dict()\n",
    "    shared_data['best_rmse'] = float('inf')\n",
    "    shared_data['best_mape'] = float('inf')\n",
    "    shared_data['best_model'] = None\n",
    "    shared_data['best_parameters'] = {}\n",
    "\n",
    "    threads = []\n",
    "    # Loop over all possible combinations of parameters\n",
    "    for n_estimators in n_estimators_range:\n",
    "        for max_features in max_features_range:\n",
    "            for max_depth in max_depth_range:\n",
    "                thread = threading.Thread(target=train_model, args=(n_estimators, max_features, max_depth, shared_data))\n",
    "                threads.append(thread)\n",
    "                thread.start()\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    print(f\"The best parameters {shared_data['best_parameters']} for RMSE = {shared_data['best_rmse']}, MAPE: {shared_data['best_mape']}%\")\n",
    "\n",
    "    parallel_time = time.time() - parallel_time \n",
    "    print(f\"The threading execution time is {parallel_time}\", \"\\n\"*5)\n",
    "    return parallel_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import multiprocessing\n",
    "\n",
    "def multiprocessing_parameter_finder(n_estimators_range, max_features_range, max_depth_range):\n",
    "    print(\"*\"*20, \"Starting Multiprocessing Parameter Finder\", \"*\"*20)\n",
    "\n",
    "    parallel_time = time.time()\n",
    "\n",
    "    # Initialize variables to store the best model and its RMSE and parameters\n",
    "    shared_data = multiprocessing.Manager().dict()\n",
    "    shared_data['best_rmse'] = float('inf')\n",
    "    shared_data['best_mape'] = float('inf')\n",
    "    shared_data['best_model'] = None\n",
    "    shared_data['best_parameters'] = {}\n",
    "\n",
    "    processes = []\n",
    "    # Loop over all possible combinations of parameters\n",
    "    for n_estimators in n_estimators_range:\n",
    "        for max_features in max_features_range:\n",
    "            for max_depth in max_depth_range:\n",
    "                process = multiprocessing.Process(target=train_model, args=(n_estimators, max_features, max_depth, shared_data))\n",
    "                processes.append(process)\n",
    "                process.start()\n",
    "\n",
    "    for process in processes:\n",
    "        process.join()\n",
    "\n",
    "    print(f\"The best parameters {shared_data['best_parameters']} for RMSE = {shared_data['best_rmse']}, MAPE: {shared_data['best_mape']}%\")\n",
    "\n",
    "    parallel_time = time.time() - parallel_time \n",
    "    print(f\"The multiprocessing execution time is {parallel_time}\", \"\\n\"*5)\n",
    "    return parallel_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Starting Sequential Parameter Finder ********************\n",
      "The parameters: 10, sqrt, 1. RMSE: 62936.129262244904, MAPE: 26.860734529882123%\n",
      "The parameters: 10, sqrt, 2. RMSE: 51806.105176310826, MAPE: 20.52147680573829%\n",
      "The parameters: 10, sqrt, 5. RMSE: 34018.6946431472, MAPE: 13.846204059816515%\n",
      "The parameters: 10, sqrt, 10. RMSE: 30158.362616471855, MAPE: 11.1847373574493%\n",
      "The parameters: 10, sqrt, 20. RMSE: 30593.76147467334, MAPE: 11.148658516638926%\n",
      "The parameters: 10, sqrt, None. RMSE: 28608.440009540453, MAPE: 11.124252485645316%\n",
      "The parameters: 10, log2, 1. RMSE: 64442.107292878405, MAPE: 27.58882909655716%\n",
      "The parameters: 10, log2, 2. RMSE: 51396.530250771764, MAPE: 21.498982900746558%\n",
      "The parameters: 10, log2, 5. RMSE: 34956.394381827566, MAPE: 13.945831547616713%\n",
      "The parameters: 10, log2, 10. RMSE: 30136.927641357106, MAPE: 11.160840785213171%\n",
      "The parameters: 10, log2, 20. RMSE: 30841.310557247474, MAPE: 11.240205002153882%\n",
      "The parameters: 10, log2, None. RMSE: 29000.351214559596, MAPE: 10.98098439114081%\n",
      "The parameters: 10, None, 1. RMSE: 57823.30960766656, MAPE: 25.854236053260713%\n",
      "The parameters: 10, None, 2. RMSE: 44738.9675013081, MAPE: 19.39967435427367%\n",
      "The parameters: 10, None, 5. RMSE: 30977.339419939668, MAPE: 12.32718845204275%\n",
      "The parameters: 10, None, 10. RMSE: 26371.732325187742, MAPE: 10.387601696539232%\n",
      "The parameters: 10, None, 20. RMSE: 27582.089072839033, MAPE: 10.336644923118392%\n",
      "The parameters: 10, None, None. RMSE: 28062.104755431203, MAPE: 10.28772353916743%\n",
      "The parameters: 25, sqrt, 1. RMSE: 60720.06723428002, MAPE: 25.2463033064465%\n",
      "The parameters: 25, sqrt, 2. RMSE: 48999.969822412146, MAPE: 19.141115612087532%\n",
      "The parameters: 25, sqrt, 5. RMSE: 32317.961786662752, MAPE: 13.114437916762203%\n",
      "The parameters: 25, sqrt, 10. RMSE: 28259.543521821943, MAPE: 10.47369873275887%\n",
      "The parameters: 25, sqrt, 20. RMSE: 28601.996953881055, MAPE: 10.651671775420226%\n",
      "The parameters: 25, sqrt, None. RMSE: 28437.477716170713, MAPE: 10.650717147533856%\n",
      "The parameters: 25, log2, 1. RMSE: 62175.23336548907, MAPE: 26.103334605968907%\n",
      "The parameters: 25, log2, 2. RMSE: 49454.96222058965, MAPE: 20.009887677109557%\n",
      "The parameters: 25, log2, 5. RMSE: 34640.741335575985, MAPE: 13.585957690083541%\n",
      "The parameters: 25, log2, 10. RMSE: 29797.647023472127, MAPE: 10.802129162615948%\n",
      "The parameters: 25, log2, 20. RMSE: 28152.423144151206, MAPE: 10.113221227840645%\n",
      "The parameters: 25, log2, None. RMSE: 28624.714349076796, MAPE: 10.195238945186857%\n",
      "The parameters: 25, None, 1. RMSE: 57545.23094798376, MAPE: 25.562043938945223%\n",
      "The parameters: 25, None, 2. RMSE: 44503.99568777034, MAPE: 18.93356623365525%\n",
      "The parameters: 25, None, 5. RMSE: 30622.018751108048, MAPE: 12.284801453967585%\n",
      "The parameters: 25, None, 10. RMSE: 27253.405412634103, MAPE: 10.272632581222856%\n",
      "The parameters: 25, None, 20. RMSE: 26499.315199813544, MAPE: 10.019023380641842%\n",
      "The parameters: 25, None, None. RMSE: 27011.528848190042, MAPE: 10.057567711051357%\n",
      "The parameters: 50, sqrt, 1. RMSE: 60346.5737195233, MAPE: 25.162121091064353%\n",
      "The parameters: 50, sqrt, 2. RMSE: 48952.98192411672, MAPE: 19.219570888426375%\n",
      "The parameters: 50, sqrt, 5. RMSE: 32807.733869677046, MAPE: 12.765423020132053%\n",
      "The parameters: 50, sqrt, 10. RMSE: 28193.908384996157, MAPE: 10.30283712157863%\n",
      "The parameters: 50, sqrt, 20. RMSE: 28322.13190140527, MAPE: 10.266831234466041%\n",
      "The parameters: 50, sqrt, None. RMSE: 28253.30753002766, MAPE: 10.301610941463089%\n",
      "The parameters: 50, log2, 1. RMSE: 61769.11746990103, MAPE: 26.024888854218215%\n",
      "The parameters: 50, log2, 2. RMSE: 49973.37697266408, MAPE: 19.855069340876533%\n",
      "The parameters: 50, log2, 5. RMSE: 35272.23782970266, MAPE: 13.259237055635129%\n",
      "The parameters: 50, log2, 10. RMSE: 29337.548793235695, MAPE: 10.69972715022594%\n",
      "The parameters: 50, log2, 20. RMSE: 28219.379219234233, MAPE: 10.054841695082303%\n",
      "The parameters: 50, log2, None. RMSE: 28552.120501147994, MAPE: 10.110335561128336%\n",
      "The parameters: 50, None, 1. RMSE: 57505.08832414332, MAPE: 25.40677081979206%\n",
      "The parameters: 50, None, 2. RMSE: 44571.23631103615, MAPE: 18.993732376822592%\n",
      "The parameters: 50, None, 5. RMSE: 30578.268789069476, MAPE: 12.246352597445519%\n",
      "The parameters: 50, None, 10. RMSE: 26549.03681495154, MAPE: 10.164540522209597%\n",
      "The parameters: 50, None, 20. RMSE: 26616.753965688236, MAPE: 9.95616179407857%\n",
      "The parameters: 50, None, None. RMSE: 26659.206888314602, MAPE: 9.950072723845874%\n",
      "The parameters: 100, sqrt, 1. RMSE: 60511.413390408285, MAPE: 24.970655834062548%\n",
      "The parameters: 100, sqrt, 2. RMSE: 48423.20979308409, MAPE: 19.124218836706603%\n",
      "The parameters: 100, sqrt, 5. RMSE: 32585.44117019146, MAPE: 12.510275320688514%\n",
      "The parameters: 100, sqrt, 10. RMSE: 27940.66308571875, MAPE: 10.232467246501514%\n",
      "The parameters: 100, sqrt, 20. RMSE: 27530.724415300712, MAPE: 10.125866760621907%\n",
      "The parameters: 100, sqrt, None. RMSE: 27690.85111196373, MAPE: 10.111048513592108%\n",
      "The parameters: 100, log2, 1. RMSE: 62166.92632864128, MAPE: 25.90574767935297%\n",
      "The parameters: 100, log2, 2. RMSE: 49946.811096505524, MAPE: 19.85047840173841%\n",
      "The parameters: 100, log2, 5. RMSE: 34438.66151846642, MAPE: 13.17388786526951%\n",
      "The parameters: 100, log2, 10. RMSE: 28459.288873741767, MAPE: 10.547559689956204%\n",
      "The parameters: 100, log2, 20. RMSE: 27471.51821338425, MAPE: 9.805906069975684%\n",
      "The parameters: 100, log2, None. RMSE: 27735.747830866087, MAPE: 10.003262143296658%\n",
      "The parameters: 100, None, 1. RMSE: 57211.16615127391, MAPE: 25.025965875120264%\n",
      "The parameters: 100, None, 2. RMSE: 44472.47296968139, MAPE: 18.836095197090465%\n",
      "The parameters: 100, None, 5. RMSE: 30154.47423520161, MAPE: 12.085654020145233%\n",
      "The parameters: 100, None, 10. RMSE: 26265.099994067186, MAPE: 10.040721857978957%\n",
      "The parameters: 100, None, 20. RMSE: 26152.741599610163, MAPE: 9.913529753089874%\n",
      "The parameters: 100, None, None. RMSE: 26057.941851126383, MAPE: 9.868196740754167%\n",
      "The parameters: 200, sqrt, 1. RMSE: 60592.20080413971, MAPE: 25.348413331204604%\n",
      "The parameters: 200, sqrt, 2. RMSE: 48456.200987649645, MAPE: 19.31834333556386%\n",
      "The parameters: 200, sqrt, 5. RMSE: 32921.85786148226, MAPE: 12.593595077314337%\n",
      "The parameters: 200, sqrt, 10. RMSE: 28088.902620554447, MAPE: 10.205458456989026%\n",
      "The parameters: 200, sqrt, 20. RMSE: 27532.91156851607, MAPE: 9.99674498484024%\n",
      "The parameters: 200, sqrt, None. RMSE: 27430.923405573616, MAPE: 10.001128964051244%\n",
      "The parameters: 200, log2, 1. RMSE: 62120.39237086007, MAPE: 26.338849401949805%\n",
      "The parameters: 200, log2, 2. RMSE: 50047.12857344109, MAPE: 20.132262501400174%\n",
      "The parameters: 200, log2, 5. RMSE: 34734.445288631454, MAPE: 13.310668983679474%\n",
      "The parameters: 200, log2, 10. RMSE: 28692.19328330196, MAPE: 10.425408664401772%\n",
      "The parameters: 200, log2, 20. RMSE: 27918.172300177175, MAPE: 9.871948875899832%\n",
      "The parameters: 200, log2, None. RMSE: 28122.610919892722, MAPE: 10.075865891296619%\n",
      "The parameters: 200, None, 1. RMSE: 57330.65911329287, MAPE: 25.203756111774418%\n",
      "The parameters: 200, None, 2. RMSE: 44545.47770035227, MAPE: 18.8459387073764%\n",
      "The parameters: 200, None, 5. RMSE: 30056.99415042013, MAPE: 12.027413013145498%\n",
      "The parameters: 200, None, 10. RMSE: 26485.54967760915, MAPE: 9.968649121179467%\n",
      "The parameters: 200, None, 20. RMSE: 26191.615393143096, MAPE: 9.814804116215956%\n",
      "The parameters: 200, None, None. RMSE: 26109.529848542985, MAPE: 9.785264413857124%\n",
      "The parameters: 300, sqrt, 1. RMSE: 60929.66932059552, MAPE: 25.5233017132497%\n",
      "The parameters: 300, sqrt, 2. RMSE: 48477.515732693806, MAPE: 19.45952457308847%\n",
      "The parameters: 300, sqrt, 5. RMSE: 32739.920144412845, MAPE: 12.654260849343446%\n",
      "The parameters: 300, sqrt, 10. RMSE: 27720.206311955073, MAPE: 10.158753220059861%\n",
      "The parameters: 300, sqrt, 20. RMSE: 27459.785134152986, MAPE: 9.886952721263405%\n",
      "The parameters: 300, sqrt, None. RMSE: 27394.84596466395, MAPE: 9.923924926914179%\n",
      "The parameters: 300, log2, 1. RMSE: 62683.20415726862, MAPE: 26.538128720991566%\n",
      "The parameters: 300, log2, 2. RMSE: 50458.67950947336, MAPE: 20.275483738507045%\n",
      "The parameters: 300, log2, 5. RMSE: 34565.6574161325, MAPE: 13.300516763849002%\n",
      "The parameters: 300, log2, 10. RMSE: 28541.379624482677, MAPE: 10.42483342213683%\n",
      "The parameters: 300, log2, 20. RMSE: 27744.585234343336, MAPE: 9.924986717080374%\n",
      "The parameters: 300, log2, None. RMSE: 27972.716859688764, MAPE: 10.050994009021618%\n",
      "The parameters: 300, None, 1. RMSE: 57645.45868384868, MAPE: 25.615849754017994%\n",
      "The parameters: 300, None, 2. RMSE: 44468.13497206259, MAPE: 18.973613128632305%\n",
      "The parameters: 300, None, 5. RMSE: 30053.282347030145, MAPE: 12.040192412613166%\n",
      "The parameters: 300, None, 10. RMSE: 26435.067646149004, MAPE: 9.957708448691804%\n",
      "The parameters: 300, None, 20. RMSE: 26224.452972222785, MAPE: 9.831241564947488%\n",
      "The parameters: 300, None, None. RMSE: 26176.10432944751, MAPE: 9.801826393115594%\n",
      "The parameters: 400, sqrt, 1. RMSE: 60914.53857642404, MAPE: 25.51869058914844%\n",
      "The parameters: 400, sqrt, 2. RMSE: 48669.695843852176, MAPE: 19.530745286106946%\n",
      "The parameters: 400, sqrt, 5. RMSE: 32809.62783027221, MAPE: 12.71009467191943%\n",
      "The parameters: 400, sqrt, 10. RMSE: 27744.18030444477, MAPE: 10.125160913453673%\n",
      "The parameters: 400, sqrt, 20. RMSE: 27497.671359831445, MAPE: 9.905124417060355%\n",
      "The parameters: 400, sqrt, None. RMSE: 27418.113736521427, MAPE: 9.945984648595795%\n",
      "The parameters: 400, log2, 1. RMSE: 62661.54638863782, MAPE: 26.43424504101804%\n",
      "The parameters: 400, log2, 2. RMSE: 50422.97022602301, MAPE: 20.23343384859187%\n",
      "The parameters: 400, log2, 5. RMSE: 34496.868353168815, MAPE: 13.290480205939964%\n",
      "The parameters: 400, log2, 10. RMSE: 28518.64779526882, MAPE: 10.390264584164836%\n",
      "The parameters: 400, log2, 20. RMSE: 27800.35162861101, MAPE: 9.91776916154931%\n",
      "The parameters: 400, log2, None. RMSE: 27905.32754903062, MAPE: 10.017981777351737%\n",
      "The parameters: 400, None, 1. RMSE: 57795.7474853705, MAPE: 25.753019610226186%\n",
      "The parameters: 400, None, 2. RMSE: 44508.690046548625, MAPE: 19.00415009775348%\n",
      "The parameters: 400, None, 5. RMSE: 30246.733688359316, MAPE: 12.052665031964972%\n",
      "The parameters: 400, None, 10. RMSE: 26626.130211240506, MAPE: 9.967897691949654%\n",
      "The parameters: 400, None, 20. RMSE: 26466.61626732859, MAPE: 9.851633812842412%\n",
      "The parameters: 400, None, None. RMSE: 26362.199455330487, MAPE: 9.83203095544113%\n",
      "The best parameters {'n_estimators': 100, 'max_features': None, 'max_depth': None} for RMSE = 26057.941851126383, MAPE: 9.868196740754167%\n",
      "The sequential execution time is 64.36373686790466 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "******************** Starting Threading Parameter Finder ********************\n",
      "The parameters: 10, sqrt, 5. RMSE: 34018.6946431472, MAPE: 13.846204059816515%\n",
      "The parameters: 10, sqrt, 1. RMSE: 62936.129262244904, MAPE: 26.860734529882123%\n",
      "The parameters: 10, log2, 1. RMSE: 64442.107292878405, MAPE: 27.58882909655716%\n",
      "The parameters: 10, sqrt, 2. RMSE: 51806.105176310826, MAPE: 20.52147680573829%\n",
      "The parameters: 10, log2, 2. RMSE: 51396.530250771764, MAPE: 21.498982900746558%\n",
      "The parameters: 10, None, 2. RMSE: 44738.9675013081, MAPE: 19.39967435427367%\n",
      "The parameters: 10, None, 1. RMSE: 57823.30960766656, MAPE: 25.854236053260713%\n",
      "The parameters: 10, log2, 5. RMSE: 34956.394381827566, MAPE: 13.945831547616713%\n",
      "The parameters: 10, sqrt, 10. RMSE: 30158.362616471855, MAPE: 11.1847373574493%\n",
      "The parameters: 10, log2, None. RMSE: 29000.351214559596, MAPE: 10.98098439114081%\n",
      "The parameters: 10, sqrt, 20. RMSE: 30593.76147467334, MAPE: 11.148658516638926%\n",
      "The parameters: 10, log2, 10. RMSE: 30136.927641357106, MAPE: 11.160840785213171%\n",
      "The parameters: 10, sqrt, None. RMSE: 28608.440009540453, MAPE: 11.124252485645316%\n",
      "The parameters: 10, None, 5. RMSE: 30977.339419939668, MAPE: 12.32718845204275%\n",
      "The parameters: 10, log2, 20. RMSE: 30841.310557247474, MAPE: 11.240205002153882%\n",
      "The parameters: 10, None, 20. RMSE: 27582.089072839033, MAPE: 10.336644923118392%\n",
      "The parameters: 10, None, 10. RMSE: 26371.732325187742, MAPE: 10.387601696539232%\n",
      "The parameters: 10, None, None. RMSE: 28062.104755431203, MAPE: 10.28772353916743%\n",
      "The parameters: 25, sqrt, 1. RMSE: 60720.06723428002, MAPE: 25.2463033064465%\n",
      "The parameters: 25, sqrt, 2. RMSE: 48999.969822412146, MAPE: 19.141115612087532%\n",
      "The parameters: 25, log2, 1. RMSE: 62175.23336548907, MAPE: 26.103334605968907%\n",
      "The parameters: 25, sqrt, 5. RMSE: 32317.961786662752, MAPE: 13.114437916762203%\n",
      "The parameters: 25, None, 2. RMSE: 44503.99568777034, MAPE: 18.93356623365525%\n",
      "The parameters: 25, log2, 5. RMSE: 34640.741335575985, MAPE: 13.585957690083541%\n",
      "The parameters: 25, log2, 2. RMSE: 49454.96222058965, MAPE: 20.009887677109557%\n",
      "The parameters: 25, log2, None. RMSE: 28624.714349076796, MAPE: 10.195238945186857%\n",
      "The parameters: 25, sqrt, None. RMSE: 28437.477716170713, MAPE: 10.650717147533856%\n",
      "The parameters: 25, sqrt, 10. RMSE: 28259.543521821943, MAPE: 10.47369873275887%\n",
      "The parameters: 25, sqrt, 20. RMSE: 28601.996953881055, MAPE: 10.651671775420226%\n",
      "The parameters: 25, log2, 10. RMSE: 29797.647023472127, MAPE: 10.802129162615948%\n",
      "The parameters: 25, None, 1. RMSE: 57545.23094798376, MAPE: 25.562043938945223%\n",
      "The parameters: 25, None, None. RMSE: 27011.528848190042, MAPE: 10.057567711051357%\n",
      "The parameters: 25, log2, 20. RMSE: 28152.423144151206, MAPE: 10.113221227840645%\n",
      "The parameters: 25, None, 20. RMSE: 26499.315199813544, MAPE: 10.019023380641842%\n",
      "The parameters: 25, None, 5. RMSE: 30622.018751108048, MAPE: 12.284801453967585%\n",
      "The parameters: 25, None, 10. RMSE: 27253.405412634103, MAPE: 10.272632581222856%\n",
      "The parameters: 50, sqrt, 1. RMSE: 60346.5737195233, MAPE: 25.162121091064353%\n",
      "The parameters: 50, None, 1. RMSE: 57505.08832414332, MAPE: 25.40677081979206%\n",
      "The parameters: 50, log2, 1. RMSE: 61769.11746990103, MAPE: 26.024888854218215%\n",
      "The parameters: 50, sqrt, 2. RMSE: 48952.98192411672, MAPE: 19.219570888426375%\n",
      "The parameters: 50, log2, 2. RMSE: 49973.37697266408, MAPE: 19.855069340876533%\n",
      "The parameters: 50, log2, 10. RMSE: 29337.548793235695, MAPE: 10.69972715022594%\n",
      "The parameters: 50, sqrt, 5. RMSE: 32807.733869677046, MAPE: 12.765423020132053%\n",
      "The parameters: 50, sqrt, 20. RMSE: 28322.13190140527, MAPE: 10.266831234466041%\n",
      "The parameters: 50, None, 2. RMSE: 44571.23631103615, MAPE: 18.993732376822592%\n",
      "The parameters: 50, log2, 20. RMSE: 28219.379219234233, MAPE: 10.054841695082303%\n",
      "The parameters: 50, sqrt, 10. RMSE: 28193.908384996157, MAPE: 10.30283712157863%\n",
      "The parameters: 50, log2, None. RMSE: 28552.120501147994, MAPE: 10.110335561128336%\n",
      "The parameters: 50, sqrt, None. RMSE: 28253.30753002766, MAPE: 10.301610941463089%\n",
      "The parameters: 50, None, 5. RMSE: 30578.268789069476, MAPE: 12.246352597445519%\n",
      "The parameters: 50, log2, 5. RMSE: 35272.23782970266, MAPE: 13.259237055635129%\n",
      "The parameters: 50, None, 10. RMSE: 26549.03681495154, MAPE: 10.164540522209597%\n",
      "The parameters: 50, None, 20. RMSE: 26616.753965688236, MAPE: 9.95616179407857%\n",
      "The parameters: 100, log2, 1. RMSE: 62166.92632864128, MAPE: 25.90574767935297%\n",
      "The parameters: 100, sqrt, 2. RMSE: 48423.20979308409, MAPE: 19.124218836706603%\n",
      "The parameters: 50, None, None. RMSE: 26659.206888314602, MAPE: 9.950072723845874%\n",
      "The parameters: 100, sqrt, 5. RMSE: 32585.44117019146, MAPE: 12.510275320688514%\n",
      "The parameters: 100, sqrt, 1. RMSE: 60511.413390408285, MAPE: 24.970655834062548%\n",
      "The parameters: 100, log2, 2. RMSE: 49946.811096505524, MAPE: 19.85047840173841%\n",
      "The parameters: 100, None, 1. RMSE: 57211.16615127391, MAPE: 25.025965875120264%\n",
      "The parameters: 100, log2, 5. RMSE: 34438.66151846642, MAPE: 13.17388786526951%\n",
      "The parameters: 100, sqrt, 10. RMSE: 27940.66308571875, MAPE: 10.232467246501514%\n",
      "The parameters: 100, None, 2. RMSE: 44472.47296968139, MAPE: 18.836095197090465%\n",
      "The parameters: 100, sqrt, 20. RMSE: 27530.724415300712, MAPE: 10.125866760621907%\n",
      "The parameters: 100, log2, 10. RMSE: 28459.288873741767, MAPE: 10.547559689956204%\n",
      "The parameters: 100, sqrt, None. RMSE: 27690.85111196373, MAPE: 10.111048513592108%\n",
      "The parameters: 100, log2, 20. RMSE: 27471.51821338425, MAPE: 9.805906069975684%\n",
      "The parameters: 100, log2, None. RMSE: 27735.747830866087, MAPE: 10.003262143296658%\n",
      "The parameters: 200, sqrt, 1. RMSE: 60592.20080413971, MAPE: 25.348413331204604%\n",
      "The parameters: 100, None, 5. RMSE: 30154.47423520161, MAPE: 12.085654020145233%\n",
      "The parameters: 100, None, 20. RMSE: 26152.741599610163, MAPE: 9.913529753089874%\n",
      "The parameters: 100, None, 10. RMSE: 26265.099994067186, MAPE: 10.040721857978957%\n",
      "The parameters: 200, log2, 1. RMSE: 62120.39237086007, MAPE: 26.338849401949805%\n",
      "The parameters: 200, sqrt, 2. RMSE: 48456.200987649645, MAPE: 19.31834333556386%\n",
      "The parameters: 100, None, None. RMSE: 26057.941851126383, MAPE: 9.868196740754167%\n",
      "The parameters: 200, log2, 2. RMSE: 50047.12857344109, MAPE: 20.132262501400174%\n",
      "The parameters: 200, None, 1. RMSE: 57330.65911329287, MAPE: 25.203756111774418%\n",
      "The parameters: 200, log2, 5. RMSE: 34734.445288631454, MAPE: 13.310668983679474%\n",
      "The parameters: 200, sqrt, 5. RMSE: 32921.85786148226, MAPE: 12.593595077314337%\n",
      "The parameters: 200, log2, 10. RMSE: 28692.19328330196, MAPE: 10.425408664401772%\n",
      "The parameters: 200, log2, None. RMSE: 28122.610919892722, MAPE: 10.075865891296619%\n",
      "The parameters: 200, None, 2. RMSE: 44545.47770035227, MAPE: 18.8459387073764%\n",
      "The parameters: 200, sqrt, 10. RMSE: 28088.902620554447, MAPE: 10.205458456989026%\n",
      "The parameters: 200, log2, 20. RMSE: 27918.172300177175, MAPE: 9.871948875899832%\n",
      "The parameters: 300, sqrt, 1. RMSE: 60929.66932059552, MAPE: 25.5233017132497%\n",
      "The parameters: 200, sqrt, 20. RMSE: 27532.91156851607, MAPE: 9.99674498484024%\n",
      "The parameters: 300, log2, 1. RMSE: 62683.20415726862, MAPE: 26.538128720991566%\n",
      "The parameters: 200, sqrt, None. RMSE: 27430.923405573616, MAPE: 10.001128964051244%\n",
      "The parameters: 300, None, 1. RMSE: 57645.45868384868, MAPE: 25.615849754017994%\n",
      "The parameters: 300, sqrt, 2. RMSE: 48477.515732693806, MAPE: 19.45952457308847%\n",
      "The parameters: 300, log2, 5. RMSE: 34565.6574161325, MAPE: 13.300516763849002%\n",
      "The parameters: 300, log2, 2. RMSE: 50458.67950947336, MAPE: 20.275483738507045%\n",
      "The parameters: 300, sqrt, 5. RMSE: 32739.920144412845, MAPE: 12.654260849343446%\n",
      "The parameters: 400, sqrt, 1. RMSE: 60914.53857642404, MAPE: 25.51869058914844%\n",
      "The parameters: 300, log2, 10. RMSE: 28541.379624482677, MAPE: 10.42483342213683%\n",
      "The parameters: 400, log2, 1. RMSE: 62661.54638863782, MAPE: 26.43424504101804%\n",
      "The parameters: 200, None, 5. RMSE: 30056.99415042013, MAPE: 12.027413013145498%\n",
      "The parameters: 400, log2, 2. RMSE: 50422.97022602301, MAPE: 20.23343384859187%\n",
      "The parameters: 400, sqrt, 2. RMSE: 48669.695843852176, MAPE: 19.530745286106946%\n",
      "The parameters: 300, sqrt, 10. RMSE: 27720.206311955073, MAPE: 10.158753220059861%\n",
      "The parameters: 200, None, 10. RMSE: 26485.54967760915, MAPE: 9.968649121179467%\n",
      "The parameters: 300, None, 2. RMSE: 44468.13497206259, MAPE: 18.973613128632305%\n",
      "The parameters: 300, log2, 20. RMSE: 27744.585234343336, MAPE: 9.924986717080374%\n",
      "The parameters: 300, log2, None. RMSE: 27972.716859688764, MAPE: 10.050994009021618%\n",
      "The parameters: 300, sqrt, 20. RMSE: 27459.785134152986, MAPE: 9.886952721263405%\n",
      "The parameters: 400, None, 1. RMSE: 57795.7474853705, MAPE: 25.753019610226186%\n",
      "The parameters: 200, None, 20. RMSE: 26191.615393143096, MAPE: 9.814804116215956%\n",
      "The parameters: 400, log2, 5. RMSE: 34496.868353168815, MAPE: 13.290480205939964%\n",
      "The parameters: 300, sqrt, None. RMSE: 27394.84596466395, MAPE: 9.923924926914179%\n",
      "The parameters: 200, None, None. RMSE: 26109.529848542985, MAPE: 9.785264413857124%\n",
      "The parameters: 400, sqrt, 5. RMSE: 32809.62783027221, MAPE: 12.71009467191943%\n",
      "The parameters: 400, log2, 10. RMSE: 28518.64779526882, MAPE: 10.390264584164836%\n",
      "The parameters: 400, sqrt, 10. RMSE: 27744.18030444477, MAPE: 10.125160913453673%\n",
      "The parameters: 400, log2, None. RMSE: 27905.32754903062, MAPE: 10.017981777351737%\n",
      "The parameters: 400, log2, 20. RMSE: 27800.35162861101, MAPE: 9.91776916154931%\n",
      "The parameters: 300, None, 5. RMSE: 30053.282347030145, MAPE: 12.040192412613166%\n",
      "The parameters: 400, None, 2. RMSE: 44508.690046548625, MAPE: 19.00415009775348%\n",
      "The parameters: 400, sqrt, None. RMSE: 27418.113736521427, MAPE: 9.945984648595795%\n",
      "The parameters: 400, sqrt, 20. RMSE: 27497.671359831445, MAPE: 9.905124417060355%\n",
      "The parameters: 300, None, 10. RMSE: 26435.067646149004, MAPE: 9.957708448691804%\n",
      "The parameters: 300, None, 20. RMSE: 26224.452972222785, MAPE: 9.831241564947488%\n",
      "The parameters: 400, None, 5. RMSE: 30246.733688359316, MAPE: 12.052665031964972%\n",
      "The parameters: 300, None, None. RMSE: 26176.10432944751, MAPE: 9.801826393115594%\n",
      "The parameters: 400, None, 10. RMSE: 26626.130211240506, MAPE: 9.967897691949654%\n",
      "The parameters: 400, None, 20. RMSE: 26466.61626732859, MAPE: 9.851633812842412%\n",
      "The parameters: 400, None, None. RMSE: 26362.199455330487, MAPE: 9.83203095544113%\n",
      "The best parameters {'n_estimators': 100, 'max_features': None, 'max_depth': None} for RMSE = 26057.941851126383, MAPE: 9.868196740754167%\n",
      "The threading execution time is 22.767321586608887 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "******************** Starting Multiprocessing Parameter Finder ********************\n",
      "The parameters: 10, sqrt, 1. RMSE: 62936.129262244904, MAPE: 26.860734529882123%\n",
      "The parameters: 10, sqrt, 2. RMSE: 51806.105176310826, MAPE: 20.52147680573829%\n",
      "The parameters: 10, sqrt, 5. RMSE: 34018.6946431472, MAPE: 13.846204059816515%\n",
      "The parameters: 10, sqrt, 10. RMSE: 30158.362616471855, MAPE: 11.1847373574493%\n",
      "The parameters: 10, sqrt, 20. RMSE: 30593.76147467334, MAPE: 11.148658516638926%\n",
      "\n",
      "The parameters: 10, log2, 1. RMSE: 64442.107292878405, MAPE: 27.58882909655716%The parameters: 10, sqrt, None. RMSE: 28608.440009540453, MAPE: 11.124252485645316%\n",
      "The parameters: 10, log2, 2. RMSE: 51396.530250771764, MAPE: 21.498982900746558%\n",
      "The parameters: 10, log2, 5. RMSE: 34956.394381827566, MAPE: 13.945831547616713%\n",
      "The parameters: 10, log2, 10. RMSE: 30136.927641357106, MAPE: 11.160840785213171%\n",
      "The parameters: 10, log2, 20. RMSE: 30841.310557247474, MAPE: 11.240205002153882%\n",
      "The parameters: 10, log2, None. RMSE: 29000.351214559596, MAPE: 10.98098439114081%\n",
      "The parameters: 10, None, 1. RMSE: 57823.30960766656, MAPE: 25.854236053260713%\n",
      "The parameters: 10, None, 2. RMSE: 44738.9675013081, MAPE: 19.39967435427367%\n",
      "The parameters: 10, None, 5. RMSE: 30977.339419939668, MAPE: 12.32718845204275%\n",
      "The parameters: 25, sqrt, 1. RMSE: 60720.06723428002, MAPE: 25.2463033064465%The parameters: 10, None, 10. RMSE: 26371.732325187742, MAPE: 10.387601696539232%\n",
      "\n",
      "The parameters: 25, sqrt, 2. RMSE: 48999.969822412146, MAPE: 19.141115612087532%\n",
      "The parameters: 25, sqrt, 5. RMSE: 32317.961786662752, MAPE: 13.114437916762203%The parameters: 10, None, 20. RMSE: 27582.089072839033, MAPE: 10.336644923118392%\n",
      "\n",
      "The parameters: 25, sqrt, 10. RMSE: 28259.543521821943, MAPE: 10.47369873275887%The parameters: 10, None, None. RMSE: 28062.104755431203, MAPE: 10.28772353916743%The parameters: 25, log2, 1. RMSE: 62175.23336548907, MAPE: 26.103334605968907%\n",
      "\n",
      "\n",
      "The parameters: 25, sqrt, None. RMSE: 28437.477716170713, MAPE: 10.650717147533856%The parameters: 25, log2, 2. RMSE: 49454.96222058965, MAPE: 20.009887677109557%\n",
      "The parameters: 25, sqrt, 20. RMSE: 28601.996953881055, MAPE: 10.651671775420226%\n",
      "\n",
      "The parameters: 25, log2, 5. RMSE: 34640.741335575985, MAPE: 13.585957690083541%\n",
      "The parameters: 25, log2, 10. RMSE: 29797.647023472127, MAPE: 10.802129162615948%\n",
      "The parameters: 25, log2, 20. RMSE: 28152.423144151206, MAPE: 10.113221227840645%\n",
      "The parameters: 25, log2, None. RMSE: 28624.714349076796, MAPE: 10.195238945186857%\n",
      "The parameters: 25, None, 1. RMSE: 57545.23094798376, MAPE: 25.562043938945223%\n",
      "The parameters: 25, None, 2. RMSE: 44503.99568777034, MAPE: 18.93356623365525%\n",
      "The parameters: 25, None, 5. RMSE: 30622.018751108048, MAPE: 12.284801453967585%\n",
      "The parameters: 50, sqrt, 1. RMSE: 60346.5737195233, MAPE: 25.162121091064353%The parameters: 50, sqrt, 2. RMSE: 48952.98192411672, MAPE: 19.219570888426375%\n",
      "\n",
      "The parameters: 50, sqrt, 5. RMSE: 32807.733869677046, MAPE: 12.765423020132053%\n",
      "The parameters: 50, log2, 1. RMSE: 61769.11746990103, MAPE: 26.024888854218215%The parameters: 50, sqrt, 10. RMSE: 28193.908384996157, MAPE: 10.30283712157863%The parameters: 50, log2, 2. RMSE: 49973.37697266408, MAPE: 19.855069340876533%\n",
      "The parameters: 25, None, 20. RMSE: 26499.315199813544, MAPE: 10.019023380641842%The parameters: 25, None, 10. RMSE: 27253.405412634103, MAPE: 10.272632581222856%\n",
      "\n",
      "\n",
      "\n",
      "The parameters: 50, sqrt, 20. RMSE: 28322.13190140527, MAPE: 10.266831234466041%\n",
      "The parameters: 50, sqrt, None. RMSE: 28253.30753002766, MAPE: 10.301610941463089%\n",
      "The parameters: 25, None, None. RMSE: 27011.528848190042, MAPE: 10.057567711051357%\n",
      "The parameters: 50, log2, 5. RMSE: 35272.23782970266, MAPE: 13.259237055635129%\n",
      "The parameters: 50, log2, 10. RMSE: 29337.548793235695, MAPE: 10.69972715022594%\n",
      "The parameters: 50, log2, None. RMSE: 28552.120501147994, MAPE: 10.110335561128336%\n",
      "The parameters: 50, None, 1. RMSE: 57505.08832414332, MAPE: 25.40677081979206%The parameters: 50, log2, 20. RMSE: 28219.379219234233, MAPE: 10.054841695082303%\n",
      "The parameters: 50, None, 2. RMSE: 44571.23631103615, MAPE: 18.993732376822592%\n",
      "\n",
      "The parameters: 100, sqrt, 1. RMSE: 60511.413390408285, MAPE: 24.970655834062548%\n",
      "The parameters: 100, sqrt, 2. RMSE: 48423.20979308409, MAPE: 19.124218836706603%The parameters: 100, sqrt, 5. RMSE: 32585.44117019146, MAPE: 12.510275320688514%The parameters: 50, None, 5. RMSE: 30578.268789069476, MAPE: 12.246352597445519%\n",
      "\n",
      "\n",
      "The parameters: 100, log2, 1. RMSE: 62166.92632864128, MAPE: 25.90574767935297%\n",
      "The parameters: 100, log2, 2. RMSE: 49946.811096505524, MAPE: 19.85047840173841%\n",
      "The parameters: 100, sqrt, 10. RMSE: 27940.66308571875, MAPE: 10.232467246501514%The parameters: 50, None, 10. RMSE: 26549.03681495154, MAPE: 10.164540522209597%The parameters: 100, sqrt, None. RMSE: 27690.85111196373, MAPE: 10.111048513592108%The parameters: 100, log2, 5. RMSE: 34438.66151846642, MAPE: 13.17388786526951%\n",
      "\n",
      "\n",
      "\n",
      "The parameters: 100, sqrt, 20. RMSE: 27530.724415300712, MAPE: 10.125866760621907%\n",
      "The parameters: 100, None, 1. RMSE: 57211.16615127391, MAPE: 25.025965875120264%\n",
      "The parameters: 100, log2, 10. RMSE: 28459.288873741767, MAPE: 10.547559689956204%The parameters: 100, log2, 20. RMSE: 27471.51821338425, MAPE: 9.805906069975684%\n",
      "\n",
      "The parameters: 100, log2, None. RMSE: 27735.747830866087, MAPE: 10.003262143296658%\n",
      "The parameters: 200, sqrt, 1. RMSE: 60592.20080413971, MAPE: 25.348413331204604%\n",
      "The parameters: 100, None, 2. RMSE: 44472.47296968139, MAPE: 18.836095197090465%\n",
      "The parameters: 50, None, 20. RMSE: 26616.753965688236, MAPE: 9.95616179407857%The parameters: 200, sqrt, 2. RMSE: 48456.200987649645, MAPE: 19.31834333556386%The parameters: 50, None, None. RMSE: 26659.206888314602, MAPE: 9.950072723845874%\n",
      "\n",
      "\n",
      "The parameters: 200, log2, 1. RMSE: 62120.39237086007, MAPE: 26.338849401949805%\n",
      "The parameters: 100, None, 5. RMSE: 30154.47423520161, MAPE: 12.085654020145233%The parameters: 200, sqrt, 5. RMSE: 32921.85786148226, MAPE: 12.593595077314337%\n",
      "\n",
      "The parameters: 200, log2, 2. RMSE: 50047.12857344109, MAPE: 20.132262501400174%\n",
      "The parameters: 200, log2, 5. RMSE: 34734.445288631454, MAPE: 13.310668983679474%\n",
      "The parameters: 200, sqrt, 10. RMSE: 28088.902620554447, MAPE: 10.205458456989026%\n",
      "The parameters: 200, log2, 10. RMSE: 28692.19328330196, MAPE: 10.425408664401772%\n",
      "The parameters: 200, sqrt, 20. RMSE: 27532.91156851607, MAPE: 9.99674498484024%The parameters: 200, sqrt, None. RMSE: 27430.923405573616, MAPE: 10.001128964051244%\n",
      "\n",
      "The parameters: 200, None, 1. RMSE: 57330.65911329287, MAPE: 25.203756111774418%The parameters: 200, log2, 20. RMSE: 27918.172300177175, MAPE: 9.871948875899832%The parameters: 300, sqrt, 1. RMSE: 60929.66932059552, MAPE: 25.5233017132497%\n",
      "\n",
      "\n",
      "The parameters: 200, log2, None. RMSE: 28122.610919892722, MAPE: 10.075865891296619%\n",
      "The parameters: 300, sqrt, 2. RMSE: 48477.515732693806, MAPE: 19.45952457308847%\n",
      "The parameters: 200, None, 2. RMSE: 44545.47770035227, MAPE: 18.8459387073764%The parameters: 300, log2, 1. RMSE: 62683.20415726862, MAPE: 26.538128720991566%\n",
      "\n",
      "The parameters: 100, None, 10. RMSE: 26265.099994067186, MAPE: 10.040721857978957%\n",
      "The parameters: 300, log2, 2. RMSE: 50458.67950947336, MAPE: 20.275483738507045%The parameters: 300, sqrt, 5. RMSE: 32739.920144412845, MAPE: 12.654260849343446%\n",
      "\n",
      "The parameters: 300, log2, 5. RMSE: 34565.6574161325, MAPE: 13.300516763849002%\n",
      "The parameters: 300, sqrt, 10. RMSE: 27720.206311955073, MAPE: 10.158753220059861%The parameters: 100, None, None. RMSE: 26057.941851126383, MAPE: 9.868196740754167%\n",
      "\n",
      "The parameters: 300, log2, 10. RMSE: 28541.379624482677, MAPE: 10.42483342213683%The parameters: 400, sqrt, 1. RMSE: 60914.53857642404, MAPE: 25.51869058914844%The parameters: 100, None, 20. RMSE: 26152.741599610163, MAPE: 9.913529753089874%\n",
      "\n",
      "\n",
      "The parameters: 400, sqrt, 2. RMSE: 48669.695843852176, MAPE: 19.530745286106946%\n",
      "The parameters: 300, None, 1. RMSE: 57645.45868384868, MAPE: 25.615849754017994%\n",
      "The parameters: 300, sqrt, None. RMSE: 27394.84596466395, MAPE: 9.923924926914179%\n",
      "The parameters: 400, log2, 1. RMSE: 62661.54638863782, MAPE: 26.43424504101804%The parameters: 300, log2, None. RMSE: 27972.716859688764, MAPE: 10.050994009021618%\n",
      "\n",
      "The parameters: 300, log2, 20. RMSE: 27744.585234343336, MAPE: 9.924986717080374%\n",
      "The parameters: 300, sqrt, 20. RMSE: 27459.785134152986, MAPE: 9.886952721263405%\n",
      "The parameters: 400, log2, 2. RMSE: 50422.97022602301, MAPE: 20.23343384859187%\n",
      "The parameters: 400, sqrt, 5. RMSE: 32809.62783027221, MAPE: 12.71009467191943%\n",
      "The parameters: 200, None, 5. RMSE: 30056.99415042013, MAPE: 12.027413013145498%\n",
      "The parameters: 400, log2, 5. RMSE: 34496.868353168815, MAPE: 13.290480205939964%\n",
      "The parameters: 300, None, 2. RMSE: 44468.13497206259, MAPE: 18.973613128632305%\n",
      "The parameters: 400, sqrt, 10. RMSE: 27744.18030444477, MAPE: 10.125160913453673%\n",
      "The parameters: 400, log2, 10. RMSE: 28518.64779526882, MAPE: 10.390264584164836%\n",
      "The parameters: 400, None, 1. RMSE: 57795.7474853705, MAPE: 25.753019610226186%\n",
      "The parameters: 400, sqrt, 20. RMSE: 27497.671359831445, MAPE: 9.905124417060355%\n",
      "The parameters: 400, sqrt, None. RMSE: 27418.113736521427, MAPE: 9.945984648595795%\n",
      "The parameters: 400, log2, 20. RMSE: 27800.35162861101, MAPE: 9.91776916154931%\n",
      "The parameters: 400, log2, None. RMSE: 27905.32754903062, MAPE: 10.017981777351737%\n",
      "The parameters: 400, None, 2. RMSE: 44508.690046548625, MAPE: 19.00415009775348%\n",
      "The parameters: 300, None, 5. RMSE: 30053.282347030145, MAPE: 12.040192412613166%\n",
      "The parameters: 200, None, 10. RMSE: 26485.54967760915, MAPE: 9.968649121179467%\n",
      "The parameters: 200, None, None. RMSE: 26109.529848542985, MAPE: 9.785264413857124%\n",
      "The parameters: 200, None, 20. RMSE: 26191.615393143096, MAPE: 9.814804116215956%\n",
      "The parameters: 400, None, 5. RMSE: 30246.733688359316, MAPE: 12.052665031964972%\n",
      "The parameters: 300, None, 10. RMSE: 26435.067646149004, MAPE: 9.957708448691804%\n",
      "The parameters: 300, None, 20. RMSE: 26224.452972222785, MAPE: 9.831241564947488%\n",
      "The parameters: 300, None, None. RMSE: 26176.10432944751, MAPE: 9.801826393115594%\n",
      "The parameters: 400, None, 10. RMSE: 26626.130211240506, MAPE: 9.967897691949654%\n",
      "The parameters: 400, None, 20. RMSE: 26466.61626732859, MAPE: 9.851633812842412%\n",
      "The parameters: 400, None, None. RMSE: 26362.199455330487, MAPE: 9.83203095544113%\n",
      "The best parameters {'n_estimators': 100, 'max_features': None, 'max_depth': None} for RMSE = 26057.941851126383, MAPE: 9.868196740754167%\n",
      "The multiprocessing execution time is 14.014272689819336 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The total execution time is 101.24370074272156\n"
     ]
    }
   ],
   "source": [
    "total_time = time.time()\n",
    "\n",
    "# Preprocess the data and split\n",
    "X_train_filled, X_val_filled, y_train, y_val = data_preprocessing()\n",
    "\n",
    "# Define the parameter ranges\n",
    "n_estimators_range = [10, 25, 50, 100, 200, 300, 400]\n",
    "max_features_range = ['sqrt', 'log2', None]  # None means using all features\n",
    "max_depth_range = [1, 2, 5, 10, 20, None]  # None means no limit\n",
    "\n",
    "# Run sequential, threading, and multiprocessing parameter finder\n",
    "sequential_time = sequential_parameter_finder(n_estimators_range, max_features_range, max_depth_range)\n",
    "threading_time = threading_parameter_finder(n_estimators_range, max_features_range, max_depth_range)\n",
    "multiprocessing_time = multiprocessing_parameter_finder(n_estimators_range, max_features_range, max_depth_range)\n",
    "\n",
    "total_time =  time.time() - total_time\n",
    "print(f\"The total execution time is {total_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAiOJJREFUeJzs3Xl0FFX+/vGnA2SFJISQhACBCFGCrIIgyioomyjCiCAoKF9BBdkcRWZAFhkjboMiizoIMuIw4iA6OKBsgiiibCIQMGAgKgRoMISQEJbc3x/80tJk64ROdZb365w+J111u+rTlUr1zdNVt2zGGCMAAAAAAADAQl6eLgAAAAAAAADlD6EUAAAAAAAALEcoBQAAAAAAAMsRSgEAAAAAAMByhFIAAAAAAACwHKEUAAAAAAAALEcoBQAAAAAAAMsRSgEAAAAAAMByhFIAAAAAAACwHKEU4CFTpkyRzWYr0msXLlwom82mQ4cOubeoKxw6dEg2m00LFy4stnXkZciQIapbt67l681ms9k0ZcoUj63fVXXr1tWQIUOKfT257QtDhgxR5cqVi33d2UrL7wQAUHp9//33uvXWWxUQECCbzaadO3d6uiS3sKLfmBer+iq5+fLLL2Wz2fTll196ZP2usrLPndu+ULduXd11113Fvm6p9PxOYC1CKaCQ9uzZo0GDBqlmzZry8fFRZGSkBg4cqD179ni6NI85dOiQHn74YdWrV0++vr6KiIhQ+/btNXnyZMtr6dixo2w2m+MREhKim2++We+++66ysrIsr8dVV9bt5eWlwMBA3XDDDXrwwQe1evVqt63nf//7X4kNd0pybQBQWmT/07l161aP1XDl53B+j5L0j+mFCxd033336dSpU/r73/+uf/7zn6pTp46ny7Lcpk2b1L17d9WsWVO+vr6KiopSr1699MEHH1hey5X7ipeXlyIjI3XnnXeWqP0mN1fWXbFiRYWEhKhFixYaPXq09u7d67b1zJkzxyNfHruiJNeGkqeipwsASpNly5ZpwIABCgkJ0dChQxUdHa1Dhw5p/vz5+uijj7RkyRLde++9Li1r4sSJevbZZ4tUx4MPPqj+/fvLx8enSK93pwMHDujmm2+Wn5+fHnnkEdWtW1dHjx7V9u3bNWPGDE2dOtXymmrVqqW4uDhJ0okTJ7Ro0SINHTpUP/30k1588cUCX5+RkaGKFa0/PF5Z99mzZ3XgwAEtW7ZM77//vvr166f3339flSpVcrTfv3+/vLwK993C//73P82ePbtQ4U+dOnWUkZHhtO7ikF9tnvqdAAAK75///KfT80WLFmn16tU5psfGxlpZVr4OHjyow4cP65133tH//d//ebocj1i6dKnuv/9+NWvWTKNHj1bVqlWVmJiojRs36p133tEDDzxgeU133HGHHnroIRljlJiYqDlz5uj222/XZ599pu7du+f72vbt2ysjI0Pe3t4WVfuHK+s+ffq0fvjhB7333nuaM2eOZsyYoXHjxjnaFrWfNWfOHIWGhhbqTDSr/ofIqzZP/k5QctHDB1x08OBBPfjgg7ruuuu0ceNGVa9e3TFv9OjRateunR588EHt2rVL1113XZ7LOXv2rAICAlSxYsUi/5NdoUIFVahQoUivdbe///3vSktL086dO3N8o3j8+HGP1BQUFKRBgwY5ng8fPlw33HCD3nzzTT3//PO5fuhnZWXp/Pnz8vX1la+vr5XlOlxdtyS9+OKLGjVqlObMmaO6detqxowZjnnF3aG4ePGisrKy5O3t7bFtks3T6wcAuO7qz7Jvv/1Wq1evzjH9aunp6fL39y/O0vKU3WcJDg522zKz+3ylxZQpU9SwYUN9++23OUIDT/Xprr/+eqf95t5771WTJk00c+bMPEOpc+fOydvbW15eXh7rP1xdt3S5T9erVy899dRTatCggXr06CHp8plVxV1n9r7o6f8hPPk7QcnF5XuAi15++WWlp6fr7bffdgqkJCk0NFRvvfWWzp49q5deeskxPXvcqL179+qBBx5Q1apV1bZtW6d5V8rIyNCoUaMUGhqqKlWq6O6779Zvv/2WYzyd/K4H37Rpk1q1aiVfX19dd911WrRokdM6Tp06pT//+c9q3LixKleurMDAQHXv3l0//PBDkbbLwYMHVatWrVxPcQ8LC3N6/sknn6hnz56KjIyUj4+P6tWrp+eff16XLl0qcD1ZWVmaOXOmbrzxRvn6+io8PFzDhw/X77//XuBr/f39dcstt+js2bM6ceKEpMsdgJEjR2rx4sW68cYb5ePjo1WrVjnmXX22zm+//aahQ4c6ao+Ojtbjjz+u8+fPO9qkpKRozJgxql27tnx8fFS/fn3NmDHjmi4brFChgt544w01bNhQb775pk6fPu2Yd/U4DRcuXNDUqVMVExMjX19fVatWTW3btnVc/jdkyBDNnj3b8R6zH9If4xm88sormjlzpurVqycfHx/t3bs337EOfv75Z3Xt2lUBAQGKjIzUtGnTZIxxzM9r7ICrl5lfbdnTrv6d7NixQ927d1dgYKAqV66szp0769tvv3Vqk/238vXXX2vcuHGqXr26AgICdO+99zr2BQAoj1w5hkrSrl271KFDB/n5+alWrVqaPn26FixYcM1jFHXs2FGNGjXStm3b1L59e/n7++svf/mLJNf7C9nL2Lt3rzp16iR/f3/VrFnTqS+WbdasWbrxxhvl7++vqlWrqmXLlo5L0oYMGaIOHTpIku677z7ZbDZ17NjR8dp169apXbt2CggIUHBwsO655x7Fx8c7LT+/Pl92H+3LL79Uy5Yt5efnp8aNGzs+G5ctW6bGjRvL19dXLVq00I4dO3LUv2/fPv3pT39SSEiIfH191bJlS3366ac52u3Zs0e333670+/L1X7IwYMHdfPNN+d6FsvVfbpXXnlFt956q6pVqyY/Pz+1aNFCH330kUvruZb+UuPGjRUaGqrExERJf/QzlixZookTJ6pmzZry9/dXampqnn2QLVu2qEePHqpataoCAgLUpEkTvf76605tXN3ehVGtWjUtWbJEFStW1N/+9jfH9Nz6WcnJyXr44YdVq1Yt+fj4qEaNGrrnnnscf3N169bVnj17tGHDBkefKXufze77bNiwQU888YTCwsJUq1Ytp3m5/e1+8cUXatasmXx9fdWwYUMtW7bMaX5e4+Fevcz8asvrd7J06VK1aNFCfn5+Cg0N1aBBg/Tbb785tckez/S3335T7969VblyZVWvXl1//vOfXfpfAiUXZ0oBLvrvf/+runXrql27drnOb9++verWravPPvssx7z77rtPMTExeuGFF5z+Yb/akCFD9OGHH+rBBx/ULbfcog0bNqhnz54u13jgwAH96U9/0tChQzV48GC9++67GjJkiFq0aKEbb7xR0uUQYfny5brvvvsUHR2tY8eO6a233lKHDh20d+9eRUZGurw+6fIpx2vWrNG6det0++2359t24cKFqly5ssaNG6fKlStr3bp1eu6555SamqqXX34539cOHz5cCxcu1MMPP6xRo0YpMTFRb775pnbs2KGvv/66wFOef/75Z1WoUMHpG9B169bpww8/1MiRIxUaGprn4OpHjhxRq1atlJKSomHDhqlBgwb67bff9NFHHyk9PV3e3t5KT09Xhw4d9Ntvv2n48OGKiorSN998owkTJujo0aOaOXNmvvXlp0KFChowYIAmTZqkTZs25blPTJkyRXFxcfq///s/tWrVSqmpqdq6dau2b9+uO+64Q8OHD9eRI0dyvYQi24IFC3Tu3DkNGzZMPj4+CgkJybOTeOnSJXXr1k233HKLXnrpJa1atUqTJ0/WxYsXNW3atEK9R1dqu9KePXvUrl07BQYG6plnnlGlSpX01ltvqWPHjtqwYYNat27t1P7JJ59U1apVNXnyZB06dEgzZ87UyJEj9e9//7tQdQJAWeDqMfS3335Tp06dZLPZNGHCBAUEBOgf//iH287UPXnypLp3767+/ftr0KBBCg8Pl1S4/sLvv/+ubt26qU+fPurXr58++ugjjR8/Xo0bN3acSfPOO+9o1KhR+tOf/qTRo0fr3Llz2rVrl7Zs2aIHHnhAw4cPV82aNfXCCy9o1KhRuvnmmx21rFmzRt27d9d1112nKVOmKCMjQ7NmzdJtt92m7du35+g75NXnO3DggGNdgwYN0iuvvKJevXpp3rx5+stf/qInnnhCkhQXF6d+/fo5XaK/Z88e3XbbbapZs6aeffZZBQQE6MMPP1Tv3r31n//8xzF0RHJysjp16qSLFy862r399tvy8/Nz6fdRp04drV27Vr/++qsjxMjL66+/rrvvvlsDBw7U+fPntWTJEt13331asWJFvn3Xa+0v/f777/r9999Vv359p+nPP/+8vL299ec//1mZmZl5Xh62evVq3XXXXapRo4ZGjx6tiIgIxcfHa8WKFRo9erQk17d3UURFRalDhw5av369UlNTFRgYmGu7vn37as+ePXryySdVt25dHT9+XKtXr1ZSUpLq1q2rmTNn6sknn1TlypX117/+VZIc+2y2J554QtWrV9dzzz2ns2fP5ltXQkKC7r//fj322GMaPHiwFixYoPvuu0+rVq3SHXfcUaj36EptV8ru3998882Ki4vTsWPH9Prrr+vrr7/Wjh07nPruly5dUteuXdW6dWu98sorWrNmjV599VXVq1dPjz/+eKHqRAliABQoJSXFSDL33HNPvu3uvvtuI8mkpqYaY4yZPHmykWQGDBiQo232vGzbtm0zksyYMWOc2g0ZMsRIMpMnT3ZMW7BggZFkEhMTHdPq1KljJJmNGzc6ph0/ftz4+PiYp556yjHt3Llz5tKlS07rSExMND4+PmbatGlO0ySZBQsW5Pued+/ebfz8/Iwk06xZMzN69GizfPlyc/bs2Rxt09PTc0wbPny48ff3N+fOnXNMGzx4sKlTp47j+VdffWUkmcWLFzu9dtWqVTmmd+jQwTRo0MCcOHHCnDhxwsTHx5tRo0YZSaZXr16OdpKMl5eX2bNnT46art7eDz30kPHy8jLff/99jrZZWVnGGGOef/55ExAQYH766Sen+c8++6ypUKGCSUpKyvHaK3Xo0MHceOONec7/+OOPjSTz+uuvO6bVqVPHDB482PG8adOmpmfPnvmuZ8SIESa3Q3/27zswMNAcP34813lX7guDBw82ksyTTz7pmJaVlWV69uxpvL29zYkTJ4wxxqxfv95IMuvXry9wmXnVZkzO30nv3r2Nt7e3OXjwoGPakSNHTJUqVUz79u0d07L/Vrp06eL4XRljzNixY02FChVMSkpKrusDgNIq+7iX22dWNlePoU8++aSx2Wxmx44djmknT540ISEhOfoh+cnt+N6hQwcjycybNy9He1f7C9nLWLRokWNaZmamiYiIMH379nVMu+eee/L9jDXmj8+rpUuXOk1v1qyZCQsLMydPnnRM++GHH4yXl5d56KGHHNPy6/Nl99G++eYbx7TPP//cSDJ+fn7m8OHDjulvvfVWjs/Nzp07m8aNGzu996ysLHPrrbeamJgYx7QxY8YYSWbLli2OacePHzdBQUEu/b7mz59vJBlvb2/TqVMnM2nSJPPVV1/l6Dcak/N3dP78edOoUSNz++2353jvV/ZVCtNfkmSGDh1qTpw4YY4fP262bNliOnfubCSZV1991Rjzx+/tuuuuy1HT1X2QixcvmujoaFOnTh3z+++/O7W9so/g6vbOiyQzYsSIPOePHj3aSDI//PCDMSZnn+j33383kszLL7+c73puvPFG06FDhxzTs48Bbdu2NRcvXsx1Xm7/Q/znP/9xTDt9+rSpUaOGad68uWPa1f+75LfMvGq7+ndy/vx5ExYWZho1amQyMjIc7VasWGEkmeeee84xLbvveeX/K8YY07x5c9OiRYsc60LpweV7gAvOnDkjSapSpUq+7bLnp6amOk1/7LHHClxH9qVj2d+UZXvyySddrrNhw4ZOZ3JVr15dN9xwg37++WfHNB8fH8c3b5cuXdLJkydVuXJl3XDDDdq+fbvL68p24403aufOnRo0aJAOHTqk119/Xb1791Z4eLjeeecdp7ZXflN35swZ2e12tWvXTunp6dq3b1+e61i6dKmCgoJ0xx13yG63Ox4tWrRQ5cqVtX79eqf2+/btU/Xq1VW9enXFxsZq1qxZ6tmzp959912ndh06dFDDhg3zfX9ZWVlavny5evXqpZYtW+aYn30a89KlS9WuXTtVrVrVqcYuXbro0qVL2rhxY77rKUjlypUl/bEv5iY4OFh79uxRQkJCkdfTt2/fHJen5mfkyJGOn7MviTx//rzWrFlT5BoKcunSJX3xxRfq3bu30/htNWrU0AMPPKBNmzbl+BscNmyY0ynn7dq106VLl3T48OFiqxMASqLCHENXrVqlNm3aqFmzZo52ISEhGjhwoFtq8fHx0cMPP5xjemH6C5UrV3Yau8fb21utWrVy6vsEBwfr119/1ffff1+o+o4ePaqdO3dqyJAhCgkJcUxv0qSJ7rjjDv3vf//L8Zq8+nwNGzZUmzZtHM+zz0a7/fbbFRUVlWN6dv2nTp3SunXr1K9fP8e2sNvtOnnypLp27aqEhATHZU7/+9//dMstt6hVq1aO5VWvXt3l39cjjzyiVatWqWPHjtq0aZOef/55tWvXTjExMfrmm2+c2l75O/r99991+vRptWvXrsC+ZGH7S/Pnz1f16tUVFham1q1bOy7HHzNmjFO7wYMHF3hG2I4dO5SYmKgxY8bkGDssu49QmO1dVAX16fz8/OTt7a0vv/zSpWEq8vLoo4+6PH5UZGSk0xlggYGBeuihh7Rjxw4lJycXuYaCbN26VcePH9cTTzzhNNZUz5491aBBg1yvQLn6b6xdu3ZOf+8ofbh8D3BBdtiUXyBw5fyrw6vo6OgC13H48GF5eXnlaHv16cn5ubJTk61q1apOH2hZWVl6/fXXNWfOHCUmJjpdg12tWjWX13Wl66+/Xv/85z916dIl7d27VytWrNBLL72kYcOGKTo6Wl26dJF0+XToiRMnat26dTlCgyvHSrpaQkKCTp8+nWM8g2xXD75Zt25dvfPOO46BI2NiYnJ9rSu/lxMnTig1NVWNGjXKt11CQoJ27dqVZ6BzrQOEpqWlSco/GJ02bZruueceXX/99WrUqJG6deumBx98UE2aNHF5Pa5sk2xeXl45BvW//vrrJemaxhkpyIkTJ5Senq4bbrghx7zY2FhlZWXpl19+cVyyKuX826hataokXVNnDwBKo8IcQw8fPuwUpGS7um9y+vRpZWRkOJ57e3s7hTh5qVmzZq6XWRWmv1CrVq0c49xUrVpVu3btcjwfP3681qxZo1atWql+/fq688479cADD+i2227Lt77sLy7y2laff/55jsHM8/ocvfpzKCgoSJJUu3btXKdnfz4dOHBAxhhNmjRJkyZNynXZx48fV82aNXX48OEcl6/nVX9eunbtqq5duyo9PV3btm3Tv//9b82bN0933XWX9u3b5+hPrVixQtOnT9fOnTuVmZnpeH1uYw5dqbD9pXvuuUcjR46UzWZTlSpVdOONN+Y6eLwr/ZeDBw9KUr59usJs76IqqE/n4+OjGTNm6KmnnlJ4eLhuueUW3XXXXXrooYcUERHh8noK06erX79+jt/dlX26wqy3MPL7G2vQoIE2bdrkNM3X1zfHvnP1/zoofQilABcEBQWpRo0aTh2c3OzatUs1a9bMcX24q9fyX6u8vg0xV4xp8MILL2jSpEl65JFH9PzzzyskJEReXl4aM2bMNQ3Inb3+xo0bq3HjxmrTpo06deqkxYsXq0uXLkpJSVGHDh0UGBioadOmqV69evL19dX27ds1fvz4fNedlZWlsLAwLV68ONf5V384BQQEOIKw/Ljz95KVlaU77rhDzzzzTK7zsz/Yi2r37t2S8g8p27dvr4MHD+qTTz7RF198oX/84x/6+9//rnnz5rl8e2t376t5dU6tHpDSlb8NAEDRjB49Wu+9957jeYcOHXIMZJyb3D5zCttfcOX4Hhsbq/3792vFihVatWqV/vOf/2jOnDl67rnnNHXqVBffpWvy+hzNq86C6s9+v3/+85/VtWvXXNsW5gtMV/n7+6tdu3Zq166dQkNDNXXqVK1cuVKDBw/WV199pbvvvlvt27fXnDlzVKNGDVWqVEkLFixwDB6fl8L2l2rVqmVpn86K7b17925VqFAh39BozJgx6tWrl5YvX67PP/9ckyZNUlxcnNatW6fmzZu7tJ6y2KcrKXcfh3sRSgEuuuuuu/TOO+9o06ZNjrupXOmrr77SoUOHNHz48CItv06dOsrKylJiYqJiYmIc0w8cOFDkmnPz0UcfqVOnTpo/f77T9JSUFIWGhrptPdmXuh09elTS5bttnDx5UsuWLVP79u0d7bLvnpKfevXqac2aNbrtttssC/iyVa9eXYGBgY5QKC/16tVTWlqaSx2nwrp06ZI++OAD+fv757rvXSkkJEQPP/ywHn74YaWlpal9+/aaMmWKI5Qq6BvMwsjKytLPP//s1IH86aefJMkx8Gv2GUkpKSlOr83tsjlXa6tevbr8/f21f//+HPP27dsnLy+vHN88AwAuK8wxtE6dOrn2Q66e9swzzzhdQpd97C+Ka+kv5CcgIED333+/7r//fp0/f159+vTR3/72N02YMCHPW9Rn31k4r20VGhqa61k77pR9RnKlSpUK7GPUqVMn10v4c6u/MK7u0/3nP/+Rr6+vPv/8c6dB7xcsWFDgsoqzv+TKuqXLoVBe6y/M9i6KpKQkbdiwQW3atClwWJB69erpqaee0lNPPaWEhAQ1a9ZMr776qt5//31J7u3TZZ8hduUy8+vTXXn547X06a78G7v6hkn79+/P9e7eKHsYUwpw0dNPPy0/Pz8NHz5cJ0+edJp36tQpPfbYY/L399fTTz9dpOVnfxszZ84cp+mzZs0qWsF5qFChQo6zQ5YuXVrk6+O/+uorXbhwIcf07HEWsk/Hzf5m48p1nz9/Psf7zU2/fv106dIlPf/88znmXbx4MUfg4U5eXl7q3bu3/vvf/2rr1q055me/n379+mnz5s36/PPPc7RJSUnRxYsXi7T+S5cuadSoUYqPj9eoUaPyvEuLpBz7ZeXKlVW/fn2n0+qzO8/u2mZvvvmm42djjN58801VqlRJnTt3lnS5s1GhQoUcY0Tk9nt3tbYKFSrozjvv1CeffOJ0meCxY8f0wQcfqG3btvluJwAozwpzDO3atas2b96snTt3OtqdOnUqx5nLDRs2VJcuXRyPFi1aXFN9UtH6C3m5+vPR29tbDRs2lDEm1z5Mtho1aqhZs2Z67733nD6bdu/erS+++EI9evQock2uCgsLU8eOHfXWW285QqErnThxwvFzjx499O233+q7775zmp/XmeZXW7t2ba7Tc+vT2Ww2pzNkDh06pOXLlxe4juLqL7nipptuUnR0tGbOnJmjr5G9vxVmexfWqVOnNGDAAF26dMlxV7rcpKen69y5c07T6tWrpypVquTo07mrP3fkyBF9/PHHjuepqalatGiRmjVr5rh0LzvUu7JPd/bsWaezJAtbW8uWLRUWFqZ58+Y5vbeVK1cqPj6+UHchR+nFmVKAi2JiYvTee+9p4MCBaty4sYYOHaro6GgdOnRI8+fPl91u17/+9S/HAbuwWrRoob59+2rmzJk6efKkbrnlFm3YsMHxLYW7vg256667NG3aND388MO69dZb9eOPP2rx4sU5xgZy1YwZM7Rt2zb16dPHMXbR9u3btWjRIoWEhDgGorz11ltVtWpVDR48WKNGjZLNZtM///lPly6f6tChg4YPH664uDjt3LlTd955pypVqqSEhAQtXbpUr7/+uv70pz8VqX5XvPDCC/riiy/UoUMHDRs2TLGxsTp69KiWLl2qTZs2KTg4WE8//bQ+/fRT3XXXXRoyZIhatGihs2fP6scff9RHH32kQ4cOFXgm2unTpx3ffqWnp+vAgQNatmyZDh48qP79++cayl2pYcOG6tixo1q0aKGQkBBt3bpVH330kdNg5Nn/KIwaNUpdu3ZVhQoV1L9//yJtF19fX61atUqDBw9W69attXLlSn322Wf6y1/+4rikMigoSPfdd59mzZolm82mevXqacWKFbmOsVWY2qZPn67Vq1erbdu2euKJJ1SxYkW99dZbyszM1EsvvVSk9wMAZcm7777ruInKlUaPHu3yMfSZZ57R+++/rzvuuENPPvmkAgIC9I9//ENRUVE6deqUW8/UyHYt/YW83HnnnYqIiNBtt92m8PBwxcfH680331TPnj0LPFvl5ZdfVvfu3dWmTRsNHTpUGRkZmjVrloKCgjRlypQi11QYs2fPVtu2bdW4cWM9+uijuu6663Ts2DFt3rxZv/76q3744QdJl39f//znP9WtWzeNHj1aAQEBevvtt1WnTp0Ch6CQLo/fFB0drV69eqlevXo6e/as1qxZo//+97+6+eab1atXL0mXB6F+7bXX1K1bNz3wwAM6fvy4Zs+erfr16xe4Hnf0l4rKy8tLc+fOVa9evdSsWTM9/PDDqlGjhvbt26c9e/Y4gjJXt3d+fvrpJ73//vsyxig1NVU//PCDli5dqrS0NMe2y++1nTt3Vr9+/dSwYUNVrFhRH3/8sY4dO+bUL2rRooXmzp2r6dOnq379+goLC8txtpGrrr/+eg0dOlTff/+9wsPD9e677+rYsWNOZ7/deeedioqK0tChQ/X000+rQoUKevfdd1W9enUlJSU5Lc/V2ipVqqQZM2bo4YcfVocOHTRgwAAdO3ZMr7/+uurWrauxY8cW6f2glLH8fn9AKbdr1y4zYMAAU6NGDVOpUiUTERFhBgwYYH788cccbbNvnXrixIk8513p7NmzZsSIESYkJMRUrlzZ9O7d2+zfv99IMi+++KKjXV63c+3Zs2eO9XTo0MHplqznzp0zTz31lKlRo4bx8/Mzt912m9m8eXOOdlffnjYvX3/9tRkxYoRp1KiRCQoKMpUqVTJRUVFmyJAhTreazm57yy23GD8/PxMZGWmeeeYZxy2Rr7z18eDBg02dOnVyrOvtt982LVq0MH5+fqZKlSqmcePG5plnnjFHjhxxer8F3fbZmPxv1yvJTJ482Wna4cOHzUMPPWSqV69ufHx8zHXXXWdGjBhhMjMzHW3OnDljJkyYYOrXr2+8vb1NaGioufXWW80rr7xizp8/n2892be1zn5UrlzZxMTEmEGDBpkvvvgi19dcfZvl6dOnm1atWpng4GDj5+dnGjRoYP72t785rfvixYvmySefNNWrVzc2m82xD2b/vnO7/XBu+8LgwYNNQECAOXjwoLnzzjuNv7+/CQ8PN5MnT85x6+gTJ06Yvn37Gn9/f1O1alUzfPhws3v37hzLzKs2Y3L/nWzfvt107drVVK5c2fj7+5tOnTo53W7bmLxvjX71LYkBoKzIPu7l9fjll1+MMa4dQ40xZseOHaZdu3bGx8fH1KpVy8TFxZk33njDSDLJycku1TRixIgcfZ78Pq9d7S/ktYyr+xFvvfWWad++valWrZrx8fEx9erVM08//bQ5ffq0o03258LSpUtzLG/NmjXmtttuM35+fiYwMND06tXL7N2716lNfn2+vPpoufVF8vo8PnjwoHnooYdMRESEqVSpkqlZs6a56667zEcffeTUbteuXaZDhw7G19fX1KxZ0zz//PNm/vz5OfqNufnXv/5l+vfvb+rVq2f8/PyMr6+vadiwofnrX/9qUlNTndrOnz/fxMTEGB8fH9OgQQOzYMGCXPu2V/dVjHG9v5RfXy1bfr+3vD7rN23aZO644w5TpUoVExAQYJo0aWJmzZrl1MbV7Z2bK//evLy8THBwsGnevLkZPXq02bNnT472V/ez7Ha7GTFihGnQoIEJCAgwQUFBpnXr1ubDDz90el1ycrLp2bOnqVKlipHk6Mfn1fe5cl5u/0N8/vnnpkmTJo7faW7bdNu2baZ169bG29vbREVFmddeey3XZeZVW16/k3//+9+mefPmxsfHx4SEhJiBAweaX3/91alNdt/zarntdyhdbMYwyitQku3cuVPNmzfX+++/77ZbMAMAABTVmDFj9NZbbyktLY2BhwEA14QxpYAS5MrbKWebOXOmvLy8nAb7BAAAsMLVfZOTJ0/qn//8p9q2bUsgBQC4ZowpBZQgL730krZt26ZOnTqpYsWKWrlypVauXKlhw4ZxNzEAAGC5Nm3aqGPHjoqNjdWxY8c0f/58paamatKkSZ4uDQBQBnD5HlCCrF69WlOnTtXevXuVlpamqKgoPfjgg/rrX/+qihXJkAEAgLX+8pe/6KOPPtKvv/4qm82mm266SZMnT1aXLl08XRoAoAwglAIAAAAAAIDlGFMKAAAAAAAAliOUAgAAAAAAgOUYpEZSVlaWjhw5oipVqshms3m6HAAAUIIYY3TmzBlFRkbKy4vv87LRfwIAAHlxtf9EKCXpyJEj3NkMAADk65dfflGtWrU8XUaJQf8JAAAUpKD+E6GUpCpVqki6vLECAwM9XA0AAChJUlNTVbt2bUd/AZfRfwIAAHlxtf9EKCU5TjkPDAykUwUAAHLFJWrO6D8BAICCFNR/YmAEAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABguYqeLgDlS1JSkux2e75tQkNDFRUVZVFFAAAAQNlE3xtASUcoBcskJSWpQWysMtLT823n5++vffHxfDgCAAAARZSUlKTYBg2UnpGRbzt/Pz/F79tH3xuARxBKwTJ2u10Z6enqN32uwqJjcm1zPDFBH058XHa7nQ9GAAAAoIjsdrvSMzK0sE93xYaG5Nom3n5KQ5atpO8NwGMIpWC5sOgY1Yxt6ukyAAAAgDIvNjREzSPDPV0GAOSKgc4BAAAAAABgOUIpAACAUmbjxo3q1auXIiMjZbPZtHz5cse8CxcuaPz48WrcuLECAgIUGRmphx56SEeOHHFaxqlTpzRw4EAFBgYqODhYQ4cOVVpamsXvBAAAlGeEUgAAAKXM2bNn1bRpU82ePTvHvPT0dG3fvl2TJk3S9u3btWzZMu3fv1933323U7uBAwdqz549Wr16tVasWKGNGzdq2LBhVr0FAAAAxpQCAAAobbp3767u3bvnOi8oKEirV692mvbmm2+qVatWSkpKUlRUlOLj47Vq1Sp9//33atmypSRp1qxZ6tGjh1555RVFRkYW+3sAAADgTCkAAIAy7vTp07LZbAoODpYkbd68WcHBwY5ASpK6dOkiLy8vbdmyJddlZGZmKjU11ekBAABwLQilAAAAyrBz585p/PjxGjBggAIDAyVJycnJCgsLc2pXsWJFhYSEKDk5OdflxMXFKSgoyPGoXbt2sdcOAADKNo+GUvkN0ilJNpst18fLL7/saFO3bt0c81988UWL3wkAAEDJc+HCBfXr10/GGM2dO/ealjVhwgSdPn3a8fjll1/cVCUAACivPDqmVPYgnY888oj69OmTY/7Ro0ednq9cuVJDhw5V3759naZPmzZNjz76qON5lSpViqdgAACAUiI7kDp8+LDWrVvnOEtKkiIiInT8+HGn9hcvXtSpU6cUERGR6/J8fHzk4+NTrDUDAIDyxaOhVH6DdErK0Sn65JNP1KlTJ1133XVO06tUqZJnBwoAAKC8yQ6kEhIStH79elWrVs1pfps2bZSSkqJt27apRYsWkqR169YpKytLrVu39kTJAACgHCo1Y0odO3ZMn332mYYOHZpj3osvvqhq1aqpefPmevnll3Xx4kUPVAgAAGCNtLQ07dy5Uzt37pQkJSYmaufOnUpKStKFCxf0pz/9SVu3btXixYt16dIlJScnKzk5WefPn5ckxcbGqlu3bnr00Uf13Xff6euvv9bIkSPVv39/7rwHAAAs49EzpQrjvffeU5UqVXJc5jdq1CjddNNNCgkJ0TfffKMJEybo6NGjeu211/JcVmZmpjIzMx3PuXsMAAAoTbZu3apOnTo5no8bN06SNHjwYE2ZMkWffvqpJKlZs2ZOr1u/fr06duwoSVq8eLFGjhypzp07y8vLS3379tUbb7xhSf0AAABSKQql3n33XQ0cOFC+vr5O07M7YZLUpEkTeXt7a/jw4YqLi8tz3IO4uDhNnTq1WOsFAAAoLh07dpQxJs/5+c3LFhISog8++MCdZQEAABRKqbh876uvvtL+/fv1f//3fwW2bd26tS5evKhDhw7l2Ya7xwAAAAAAAHhWqThTav78+WrRooWaNm1aYNudO3fKy8tLYWFhebbh7jEAAAAAAACe5dFQKi0tTQcOHHA8zx6kMyQkRFFRUZIuj/e0dOlSvfrqqzlev3nzZm3ZskWdOnVSlSpVtHnzZo0dO1aDBg1S1apVLXsfAAAAAAAAKByPhlL5DdK5cOFCSdKSJUtkjNGAAQNyvN7Hx0dLlizRlClTlJmZqejoaI0dO9ZpnCkAAAAAAACUPB4NpQoapFOShg0bpmHDhuU676abbtK3335bHKUBAAAAAACgGJWKgc4BAAAAAABQthBKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALBcRU8XgLIhKSlJdrs93zbx8fEWVQMAAAAAAEo6Qilcs6SkJDWIjVVGerqnSwEAAAAAAKUEoRSumd1uV0Z6uvpNn6uw6Jg82+3/eq1Wz4mzsDIAAAAAAFBSEUrBbcKiY1Qztmme848nJlhYDQAAAAAAKMkY6BwAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYLmKni4AAAAAAFB+JCUlyW6359smNDRUUVFRFlUEwFMIpQAAAAAAlkhKSlJsgwZKz8jIt52/n5/i9+0jmALKOEIpAAAAAIAl7Ha70jMytLBPd8WGhuTaJt5+SkOWrZTdbieUAso4QikAAAAAgKViQ0PUPDLc02UA8DAGOgcAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOY+GUhs3blSvXr0UGRkpm82m5cuXO80fMmSIbDab06Nbt25ObU6dOqWBAwcqMDBQwcHBGjp0qNLS0ix8FwAAAAAAACgsj4ZSZ8+eVdOmTTV79uw823Tr1k1Hjx51PP71r385zR84cKD27Nmj1atXa8WKFdq4caOGDRtW3KUDAAAAAADgGlT05Mq7d++u7t2759vGx8dHERERuc6Lj4/XqlWr9P3336tly5aSpFmzZqlHjx565ZVXFBkZ6faaAQAAAAAAcO1K/JhSX375pcLCwnTDDTfo8ccf18mTJx3zNm/erODgYEcgJUldunSRl5eXtmzZkucyMzMzlZqa6vQAAAAAAACAdUp0KNWtWzctWrRIa9eu1YwZM7RhwwZ1795dly5dkiQlJycrLCzM6TUVK1ZUSEiIkpOT81xuXFycgoKCHI/atWsX6/sAAAAAAACAM49evleQ/v37O35u3LixmjRponr16unLL79U586di7zcCRMmaNy4cY7nqampBFMAAAAAAAAWKtFnSl3tuuuuU2hoqA4cOCBJioiI0PHjx53aXLx4UadOncpzHCrp8jhVgYGBTg8AAIDSoqA7GBtj9Nxzz6lGjRry8/NTly5dlJCQ4NSGOxgDAABPK1Wh1K+//qqTJ0+qRo0akqQ2bdooJSVF27Ztc7RZt26dsrKy1Lp1a0+VCQAAUKwKuoPxSy+9pDfeeEPz5s3Tli1bFBAQoK5du+rcuXOONtzBGAAAeJpHL99LS0tznPUkSYmJidq5c6dCQkIUEhKiqVOnqm/fvoqIiNDBgwf1zDPPqH79+urataskKTY2Vt26ddOjjz6qefPm6cKFCxo5cqT69+/PnfcAAECZld8djI0xmjlzpiZOnKh77rlHkrRo0SKFh4dr+fLl6t+/P3cwBgAAJYJHz5TaunWrmjdvrubNm0uSxo0bp+bNm+u5555ThQoVtGvXLt199926/vrrNXToULVo0UJfffWVfHx8HMtYvHixGjRooM6dO6tHjx5q27at3n77bU+9JQAAAI9KTExUcnKyunTp4pgWFBSk1q1ba/PmzZKKfgdjAAAAd/LomVIdO3aUMSbP+Z9//nmBywgJCdEHH3zgzrIAAABKrew7EIeHhztNDw8Pd8wryh2MMzMzlZmZ6XiemprqzrIBFEJSUpLsdnu+beLj4y2qBgCKrkTffQ8AAAAlQ1xcnKZOnerpMoByLykpSbENGig9I8PTpQDANSOUAgAAKEOy70B87Ngxx81hsp83a9bM0aawdzCeMGGCxo0b53iempqq2rVru7l6AAWx2+1Kz8jQwj7dFRsakme7lQmJmrL+GwsrA4DCI5QCAAAoQ6KjoxUREaG1a9c6QqjU1FRt2bJFjz/+uCTnOxi3aNFCUsF3MPbx8XEa1xOAZ8WGhqh5ZHie8/fZT1lYDQAUDaEUAABAKZPfHYyjoqI0ZswYTZ8+XTExMYqOjtakSZMUGRmp3r17S+IOxgAAoGQglAIAAChltm7dqk6dOjmeZ19WN3jwYC1cuFDPPPOMzp49q2HDhiklJUVt27bVqlWr5Ovr63jN4sWLNXLkSHXu3FleXl7q27ev3njjDcvfCwAAKL8IpQAAAEqZgu5gbLPZNG3aNE2bNi3PNtzBGAAAeJqXpwsAAAAAAABA+UMoBQAAAAAAAMsRSgEAAAAAAMByhFIAAAAAAACwHKEUAAAAAAAALEcoBQAAAAAAAMsRSgEAAAAAAMByhFIAAAAAAACwHKEUAAAAAAAALEcoBQAAAAAAAMsRSgEAAAAAAMByhFIAAAAAAACwHKEUAAAAAAAALEcoBQAAAAAAAMsRSgEAAAAAAMByhFIAAAAAAACwHKEUAAAAAAAALEcoBQAAAAAAAMsRSgEAAAAAAMByhFIAAAAAAACwHKEUAAAAAAAALFfR0wUAAAAAADwnPj6+wDahoaGKioqyoBoA5QmhFAAAAACUQ8lpZ+Vls2nQoEEFtvX381P8vn0EUwDcilAKAAAAAMqhlHOZyjJGC/t0V2xoSJ7t4u2nNGTZStntdkIpAG5FKAUAAAAA5VhsaIiaR4Z7ugwA5RADnQMAAAAAAMByhFIAAAAAAACwHKEUAAAAAAAALMeYUgAAAACAEic+Pr7ANqGhoQy+DpRihFIAAAAAgBIjOe2svGw2DRo0qMC2/n5+it+3j2AKKKUIpQAAAAAAJUbKuUxlGaOFfborNjQkz3bx9lMasmyl7HY7oRRQShFKAQAAAABKnNjQEDWPDPd0GQCKEaEUAAAAAKBABY3xxPhOAAqLUAoAAAAAkCdXx3hifCcAhUUoBQAAAADIkytjPDG+E4CiIJQCAAAAABSIMZ4AuJuXpwsAAAAAAABA+UMoBQAAAAAAAMsRSgEAAAAAAMByhFIAAAAAAACwHAOdo9RKSkqS3W7Pt01oaCh3/wAAAAAAoAQilEKplJSUpAaxscpIT8+3nZ+/v/bFxxNMAQAAAABQwhBKoVSy2+3KSE9Xv+lzFRYdk2ub44kJ+nDi47Lb7YRSAAAAAACUMIRSKNXComNUM7app8sAAAAAAACFxEDnAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACzn0VBq48aN6tWrlyIjI2Wz2bR8+XLHvAsXLmj8+PFq3LixAgICFBkZqYceekhHjhxxWkbdunVls9mcHi+++KLF76RsS0pK0vbt2/N8xMfHe7pEAAAAAABQylT05MrPnj2rpk2b6pFHHlGfPn2c5qWnp2v79u2aNGmSmjZtqt9//12jR4/W3Xffra1btzq1nTZtmh599FHH8ypVqlhSf3mQlJSkBrGxykhP93QpAAAAAACgDPFoKNW9e3d1794913lBQUFavXq107Q333xTrVq1UlJSkqKiohzTq1SpooiIiGKttbyy2+3KSE9Xv+lzFRYdk2ub/V+v1eo5cRZXBgAAAAAASjOPhlKFdfr0adlsNgUHBztNf/HFF/X8888rKipKDzzwgMaOHauKFfN+a5mZmcrMzHQ8T01NLa6Sy4yw6BjVjG2a67zjiQkWVwMAAAAAAEq7UhNKnTt3TuPHj9eAAQMUGBjomD5q1CjddNNNCgkJ0TfffKMJEybo6NGjeu211/JcVlxcnKZOnWpF2QAAAAAAAMhFqQilLly4oH79+skYo7lz5zrNGzdunOPnJk2ayNvbW8OHD1dcXJx8fHxyXd6ECROcXpeamqratWsXT/EAAAAAAADIocSHUtmB1OHDh7Vu3Tqns6Ry07p1a128eFGHDh3SDTfckGsbHx+fPAMrAAAAAAAAFL8SHUplB1IJCQlav369qlWrVuBrdu7cKS8vL4WFhVlQIQAAAAAAAIrCo6FUWlqaDhw44HiemJionTt3KiQkRDVq1NCf/vQnbd++XStWrNClS5eUnJwsSQoJCZG3t7c2b96sLVu2qFOnTqpSpYo2b96ssWPHatCgQapataqn3hYAAAAAAAAK4NFQauvWrerUqZPjefY4T4MHD9aUKVP06aefSpKaNWvm9Lr169erY8eO8vHx0ZIlSzRlyhRlZmYqOjpaY8eOdRovCgAAAAAAACWPR0Opjh07yhiT5/z85knSTTfdpG+//dbdZQEAAAAAAKCYlegxpVB+xcfHX9N8AAAAAABQshFKoUQ5Yz8mm5eXBg0a5OlSAAAAAABAMSKUQomScSZVJitL/abPVVh0TJ7t9n+9VqvnxFlYGQAAAAAAcCdCKZRIYdExqhnbNM/5xxMTXF6WK5f6hYaGKioqyuVlAgAAAMiJYTgAFAahFMqswlwK6Ofvr33x8QRTAAAAQBEkp52Vl83GMBwACoVQCmWWq5cCHk9M0IcTH5fdbieUAgAAAIog5VymsozRwj7dFRsakme7lQmJmrL+GwsrA1CSEUqhzCvoUkAAAAAA7hEbGqLmkeF5zt9nP2VhNQBKOi9PFwAAAAD3unTpkiZNmqTo6Gj5+fmpXr16ev7552WMcbQxxui5555TjRo15Ofnpy5duighwfUxGwEAAK4VoRQAAEAZM2PGDM2dO1dvvvmm4uPjNWPGDL300kuaNWuWo81LL72kN954Q/PmzdOWLVsUEBCgrl276ty5cx6sHAAAlCdcvgcAAFDGfPPNN7rnnnvUs2dPSVLdunX1r3/9S999952ky2dJzZw5UxMnTtQ999wjSVq0aJHCw8O1fPly9e/f32O1AwCA8oMzpQAAAMqYW2+9VWvXrtVPP/0kSfrhhx+0adMmde/eXZKUmJio5ORkdenSxfGaoKAgtW7dWps3b/ZIzQAAoPzhTCkAAIAy5tlnn1VqaqoaNGigChUq6NKlS/rb3/6mgQMHSpKSk5MlSeHhzoMRh4eHO+ZdLTMzU5mZmY7nqampxVQ9AAAoLzhTCgAAoIz58MMPtXjxYn3wwQfavn273nvvPb3yyit67733irzMuLg4BQUFOR61a9d2Y8UAAKA8IpQCAAAoY55++mk9++yz6t+/vxo3bqwHH3xQY8eOVVxcnCQpIiJCknTs2DGn1x07dswx72oTJkzQ6dOnHY9ffvmleN8EAAAo8wilAAAAypj09HR5eTl38ypUqKCsrCxJUnR0tCIiIrR27VrH/NTUVG3ZskVt2rTJdZk+Pj4KDAx0egAAAFwLxpQCAAAoY3r16qW//e1vioqK0o033qgdO3botdde0yOPPCJJstlsGjNmjKZPn66YmBhFR0dr0qRJioyMVO/evT1bPAAAKDcIpQAAAMqYWbNmadKkSXriiSd0/PhxRUZGavjw4XruueccbZ555hmdPXtWw4YNU0pKitq2batVq1bJ19fXg5UDAIDyhFAKAACgjKlSpYpmzpypmTNn5tnGZrNp2rRpmjZtmnWFAQAAXIExpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAlitSKPXzzz+7uw4AAIAyjz4UAADAH4oUStWvX1+dOnXS+++/r3Pnzrm7JgAAgDKJPhQAAMAfihRKbd++XU2aNNG4ceMUERGh4cOH67vvvnN3bQAAAGUKfSgAAIA/FCmUatasmV5//XUdOXJE7777ro4ePaq2bduqUaNGeu2113TixAl31wkAAFDq0YcCAAD4wzUNdF6xYkX16dNHS5cu1YwZM3TgwAH9+c9/Vu3atfXQQw/p6NGj7qoTAACgzKAPBQAAcI2h1NatW/XEE0+oRo0aeu211/TnP/9ZBw8e1OrVq3XkyBHdc8897qoTAACgzKAPBQAAIFUsyotee+01LViwQPv371ePHj20aNEi9ejRQ15elzOu6OhoLVy4UHXr1nVnrQAAAKUafSgAAIA/FCmUmjt3rh555BENGTJENWrUyLVNWFiY5s+ff03FAQAAlCX0oQAAAP5QpFAqISGhwDbe3t4aPHhwURYPAABQJtGHAgAA+EORxpRasGCBli5dmmP60qVL9d57711zUQAAAGURfSgAAIA/FCmUiouLU2hoaI7pYWFheuGFF665KAAAgLKIPhQAAMAfihRKJSUlKTo6Osf0OnXqKCkp6ZqLAgAAKIvoQwEAAPyhSKFUWFiYdu3alWP6Dz/8oGrVql1zUQAAAGURfSgAAIA/FCmUGjBggEaNGqX169fr0qVLunTpktatW6fRo0erf//+7q4RAACgTKAPBQAA8IcihVLPP/+8Wrdurc6dO8vPz09+fn668847dfvttxdqPISNGzeqV69eioyMlM1m0/Lly53mG2P03HPPqUaNGvLz81OXLl1y3LXm1KlTGjhwoAIDAxUcHKyhQ4cqLS2tKG8LAACgWLmrDwUAAFAWFCmU8vb21r///W/t27dPixcv1rJly3Tw4EG9++678vb2dnk5Z8+eVdOmTTV79uxc57/00kt64403NG/ePG3ZskUBAQHq2rWrzp0752gzcOBA7dmzR6tXr9aKFSu0ceNGDRs2rChvCwAAoFi5qw8FAABQFlS8lhdff/31uv7664v8+u7du6t79+65zjPGaObMmZo4caLuueceSdKiRYsUHh6u5cuXq3///oqPj9eqVav0/fffq2XLlpKkWbNmqUePHnrllVcUGRlZ5NoAAACKy7X2oQAAAMqCIoVSly5d0sKFC7V27VodP35cWVlZTvPXrVt3zYUlJiYqOTlZXbp0cUwLCgpS69attXnzZvXv31+bN29WcHCwI5CSpC5dusjLy0tbtmzRvffee811AAAAuIsVfSgAAIDSokih1OjRo7Vw4UL17NlTjRo1ks1mc3ddSk5OliSFh4c7TQ8PD3fMS05OVlhYmNP8ihUrKiQkxNEmN5mZmcrMzHQ8T01NdVfZAAAAebKiDwUAAFBaFCmUWrJkiT788EP16NHD3fVYIi4uTlOnTvV0GQAAoJwp7X0oAAAAdyryQOf169d3dy1OIiIiJEnHjh1zmn7s2DHHvIiICB0/ftxp/sWLF3Xq1ClHm9xMmDBBp0+fdjx++eUXN1cPAACQkxV9KAAAgNKiSKHUU089pddff13GGHfX4xAdHa2IiAitXbvWMS01NVVbtmxRmzZtJElt2rRRSkqKtm3b5mizbt06ZWVlqXXr1nku28fHR4GBgU4PAACA4mZFHwoAAKC0KNLle5s2bdL69eu1cuVK3XjjjapUqZLT/GXLlrm0nLS0NB04cMDxPDExUTt37lRISIiioqI0ZswYTZ8+XTExMYqOjtakSZMUGRmp3r17S5JiY2PVrVs3Pfroo5o3b54uXLigkSNHqn///tx5DwAAlDju6kMBAACUBUUKpYKDg91yZ7utW7eqU6dOjufjxo2TJA0ePFgLFy7UM888o7Nnz2rYsGFKSUlR27ZttWrVKvn6+jpes3jxYo0cOVKdO3eWl5eX+vbtqzfeeOOaawMAAHA3d/WhAAAAyoIihVILFixwy8o7duyY7+nrNptN06ZN07Rp0/JsExISog8++MAt9QAAABQnd/WhAAAAyoIijSklXR5QfM2aNXrrrbd05swZSdKRI0eUlpbmtuIAAADKGvpQAAAAlxXpTKnDhw+rW7duSkpKUmZmpu644w5VqVJFM2bMUGZmpubNm+fuOgEAAEo9+lAAAAB/KNKZUqNHj1bLli31+++/y8/PzzH93nvvdbpbHgAAAP5AHwoAAOAPRTpT6quvvtI333wjb29vp+l169bVb7/95pbCAAAAyhr6UAAAAH8oUiiVlZWlS5cu5Zj+66+/qkqVKtdcFAAAQFlEHwpAQZKSkmS32/OcHx8fb2E1AFC8ihRK3XnnnZo5c6befvttSZfvkpeWlqbJkyerR48ebi0QAACgrKAPBSA/SUlJim3QQOkZGZ4uBQAsUaRQ6tVXX1XXrl3VsGFDnTt3Tg888IASEhIUGhqqf/3rX+6uEQAAoEygDwUgP3a7XekZGVrYp7tiQ0NybbMyIVFT1n9jcWUAUDyKFErVqlVLP/zwg5YsWaJdu3YpLS1NQ4cO1cCBA50G7QQAAMAf6EMBcEVsaIiaR4bnOm+f/ZTF1QBA8SlSKCVJFStW1KBBg9xZCwAAQJlHHwoA3KugcbZCQ0MVFRVlUTUACqNIodSiRYvynf/QQw8VqRgAAICyjD4UALhPctpZedlsBQb9/n5+it+3j2AKKIGKFEqNHj3a6fmFCxeUnp4ub29v+fv706ECAADIBX0oAHCflHOZyjIm3zG44u2nNGTZStntdkIpoAQqUij1+++/55iWkJCgxx9/XE8//fQ1FwUAAFAW0YcCAPfLbwwuACWbl7sWFBMToxdffDHHN4AAAADIG30oAABQXrktlJIuD9x55MgRdy4SAACgzKMPBQAAyqMiXb736aefOj03xujo0aN68803ddttt7mlMAAAgLKGPhQAAMAfihRK9e7d2+m5zWZT9erVdfvtt+vVV191R10AAABlDn0oAACAPxQplMrKynJ3HQAAAGUefSgAAIA/uHVMKQAAAAAAAMAVRTpTaty4cS63fe2114qyCgAAgDKHPhQAAMAfihRK7dixQzt27NCFCxd0ww03SJJ++uknVahQQTfddJOjnc1mc0+VAAAAZQB9KAAAgD8U6fK9Xr16qX379vr111+1fft2bd++Xb/88os6deqku+66S+vXr9f69eu1bt06d9cLAABQalnZh/rtt980aNAgVatWTX5+fmrcuLG2bt3qmG+M0XPPPacaNWrIz89PXbp0UUJCwjWvFwAAwFVFCqVeffVVxcXFqWrVqo5pVatW1fTp07lzDAAAQB6s6kP9/vvvuu2221SpUiWtXLlSe/fu1auvvuq03pdeeklvvPGG5s2bpy1btiggIEBdu3bVuXPn3FYHAABAfop0+V5qaqpOnDiRY/qJEyd05syZay4KAACgLLKqDzVjxgzVrl1bCxYscEyLjo52/GyM0cyZMzVx4kTdc889kqRFixYpPDxcy5cvV//+/d1WCwAAQF6KdKbUvffeq4cffljLli3Tr7/+ql9//VX/+c9/NHToUPXp08fdNQIAAJQJVvWhPv30U7Vs2VL33XefwsLC1Lx5c73zzjuO+YmJiUpOTlaXLl0c04KCgtS6dWtt3rw512VmZmYqNTXV6QEAAHAtihRKzZs3T927d9cDDzygOnXqqE6dOnrggQfUrVs3zZkzx901AgAAlAlW9aF+/vlnzZ07VzExMfr888/1+OOPa9SoUXrvvfckScnJyZKk8PBwp9eFh4c75l0tLi5OQUFBjkft2rXdVi8AACifinT5nr+/v+bMmaOXX35ZBw8elCTVq1dPAQEBbi0OAACgLLGqD5WVlaWWLVvqhRdekCQ1b95cu3fv1rx58zR48OAiLXPChAkaN26c43lqairBFAAAuCZFOlMq29GjR3X06FHFxMQoICBAxhh31QUAAFBmFXcfqkaNGmrYsKHTtNjYWCUlJUmSIiIiJEnHjh1zanPs2DHHvKv5+PgoMDDQ6QEAAHAtihRKnTx5Up07d9b111+vHj166OjRo5KkoUOH6qmnnnJrgQAAAGWFVX2o2267Tfv373ea9tNPP6lOnTqSLg96HhERobVr1zrmp6amasuWLWrTpo3b6gAAAMhPkUKpsWPHqlKlSkpKSpK/v79j+v33369Vq1a5rTgAAICyxKo+1NixY/Xtt9/qhRde0IEDB/TBBx/o7bff1ogRIyRJNptNY8aM0fTp0/Xpp5/qxx9/1EMPPaTIyEj17t3bbXUAAADkp0hjSn3xxRf6/PPPVatWLafpMTExOnz4sFsKAwAAKGus6kPdfPPN+vjjjzVhwgRNmzZN0dHRmjlzpgYOHOho88wzz+js2bMaNmyYUlJS1LZtW61atUq+vr5uqwMAACA/RQqlzp496/TtXrZTp07Jx8fnmosCAAAoi6zsQ911112666678pxvs9k0bdo0TZs2za3rBQAAcFWRQql27dpp0aJFev755yVd7tRkZWXppZdeUqdOndxaIAAAQFlBHwoom5KSkmS32/NtExoaqqioKIsqQlHwewSsV6RQ6qWXXlLnzp21detWnT9/Xs8884z27NmjU6dO6euvv3Z3jQAAAGUCfSig7ElKSlJsgwZKz8jIt52/n5/i9+0j0Cih+D0CnlGkUKpRo0b66aef9Oabb6pKlSpKS0tTnz59NGLECNWoUcPdNQIAAJQJ9KGAssdutys9I0ML+3RXbGhIrm3i7ac0ZNlK2e12wowSit8j4BmFDqUuXLigbt26ad68efrrX/9aHDUBAACUOfShgLItNjREzSPDPV0GrhG/R8BaXoV9QaVKlbRr167iqAUAAKDMog8FAADgrNChlCQNGjRI8+fPd3ctAAAAZRp9KAAAgD8UaUypixcv6t1339WaNWvUokULBQQEOM1/7bXX3FIcAABAWUIfCgAA4A+FCqV+/vln1a1bV7t379ZNN90kSfrpp5+c2thsNvdVBwAAUAbQhwIAAMipUKFUTEyMjh49qvXr10uS7r//fr3xxhsKD2cgOAAAgLzQhwIgSfHx8dc0HwDKmkKFUsYYp+crV67U2bNn3VoQAABAWUMfCijfktPOystm06BBgzxdCgCUKEUaUyrb1R0sAAAAFIw+FFC+pJzLVJYxWtinu2JDQ/JstzIhUVPWf2NhZQDgWYUKpWw2W47xDhj/AAAAIH/0oQBIUmxoiJpH5n3Z7j77KQurAQDPK/Tle0OGDJGPj48k6dy5c3rsscdy3Dlm2bJl7qsQAACglKMPBQCexXheQMlUqFBq8ODBTs+5JhoAAKBg9KEAwDMYzwso2QoVSi1YsKC46gAAACiz6EMBgGcwnhdQsl3TQOcAAAAAAJR0jOcFlExeni4AAAAAAAAA5Q+hFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsBx33wP+v/j4+Hznh4aGKioqyqJqAAAAAAAo2wilUO6dsR+TzctLgwYNyredn7+/9sXHE0wBAAAAAOAGhFIo9zLOpMpkZanf9LkKi47Jtc3xxAR9OPFx2e12QikAAAAAANyAUAr4/8KiY1QztqmnywAAAAAAoFwo8QOd161bVzabLcdjxIgRkqSOHTvmmPfYY495uGoAAAAAAADkp8SfKfX999/r0qVLjue7d+/WHXfcofvuu88x7dFHH9W0adMcz/39/S2tEQAAAAAAAIVT4kOp6tWrOz1/8cUXVa9ePXXo0MExzd/fXxEREVaXBgAAAAAAgCIq8aHUlc6fP6/3339f48aNk81mc0xfvHix3n//fUVERKhXr16aNGkSZ0sBAAAAANwuPj4+3/mhoaHcHAlwUakKpZYvX66UlBQNGTLEMe2BBx5QnTp1FBkZqV27dmn8+PHav3+/li1bludyMjMzlZmZ6XiemppanGUDAAAAAEq55LSz8rLZNGjQoHzb+fv5KX7fPoIpwAWlKpSaP3++unfvrsjISMe0YcOGOX5u3LixatSooc6dO+vgwYOqV69ersuJi4vT1KlTi71eAAAAAEDZkHIuU1nGaGGf7ooNDcm1Tbz9lIYsWym73U4oBbig1IRShw8f1po1a/I9A0qSWrduLUk6cOBAnqHUhAkTNG7cOMfz1NRU1a5d233FAgAAAADKpNjQEDWPDPd0GUCZUGpCqQULFigsLEw9e/bMt93OnTslSTVq1MizjY+Pj3x8fNxZHgAAAAAAAAqhVIRSWVlZWrBggQYPHqyKFf8o+eDBg/rggw/Uo0cPVatWTbt27dLYsWPVvn17NWnSxIMVAwAAAAAAID+lIpRas2aNkpKS9MgjjzhN9/b21po1azRz5kydPXtWtWvXVt++fTVx4kQPVQoAAAAAAABXlIpQ6s4775QxJsf02rVra8OGDR6oCAAAAAAAANfCy9MFAAAAAAAAoPwhlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWK6ipwsAAAAAAKAsiY+PL7BNaGiooqKiLKgGKLkIpQAAAAAAcIPktLPystk0aNCgAtv6+/kpft8+gimUa4RSAAAAAAC4Qcq5TGUZo4V9uis2NCTPdvH2UxqybKXsdjuhFMo1QikAAAAAANwoNjREzSPDPV0GUOIx0DkAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAy1X0dAFAWZOUlCS73Z5vm9DQUEVFRVlUEQAAAAAAJQ+hFOBGSUlJahAbq4z09Hzb+fn7a198PMEUAAAAAKDcIpQC3MhutysjPV39ps9VWHRMrm2OJybow4mPy263E0oBAAAAAMotQimgGIRFx6hmbFNPlwEAAAAAQInFQOcAAAAAAACwHGdKAQAAAADgAfHx8fnO5wZJKOsIpQAAAAAAsFBy2ll52WwaNGhQvu38/fwUv28fwRTKLEIpAAAAAAAslHIuU1nGaGGf7ooNDcm1Tbz9lIYsW8kNklCmEUqVUUlJSbLb7fm24VTQwivo9NqC5gMAAABAttjQEDWPDPd0GYDHEEqVQUlJSWoQG6uM9PR82/n5+2tffDzBlAvO2I/J5uVV4Om1AAAAAADANYRSZZDdbldGerr6TZ+rsOiYXNscT0zQhxMf51RQF2WcSZXJysp3m0rS/q/XavWcOAsrAwCgYC+++KImTJig0aNHa+bMmZKkc+fO6amnntKSJUuUmZmprl27as6cOQoP5xt7AABgDUKpMiwsOkY1Y5t6uowypaBtejwxwcJqAAAo2Pfff6+33npLTZo0cZo+duxYffbZZ1q6dKmCgoI0cuRI9enTR19//bWHKgUAAOWNl6cLAAAAQPFIS0vTwIED9c4776hq1aqO6adPn9b8+fP12muv6fbbb1eLFi20YMECffPNN/r22289WDEAAChPCKUAAADKqBEjRqhnz57q0qWL0/Rt27bpwoULTtMbNGigqKgobd68OddlZWZmKjU11ekBAABwLbh8DwAAoAxasmSJtm/fru+//z7HvOTkZHl7eys4ONhpenh4uJKTk3NdXlxcnKZOnVocpQIAgHKKM6UAAADKmF9++UWjR4/W4sWL5evr65ZlTpgwQadPn3Y8fvnlF7csFwAAlF+cKVXOxcfHX9N8AABQ8mzbtk3Hjx/XTTfd5Jh26dIlbdy4UW+++aY+//xznT9/XikpKU5nSx07dkwRERG5LtPHx0c+Pj7FXToAAChHCKXKqTP2Y7J5eWnQoEGeLgUAALhZ586d9eOPPzpNe/jhh9WgQQONHz9etWvXVqVKlbR27Vr17dtXkrR//34lJSWpTZs2nigZAACUQ4RS5VTGmVSZrCz1mz5XYdExebbb//VarZ4TZ2FlAADgWlWpUkWNGjVymhYQEKBq1ao5pg8dOlTjxo1TSEiIAgMD9eSTT6pNmza65ZZbPFEyAAAohwilyrmw6BjVjG2a5/zjiQkWVgMAAKzy97//XV5eXurbt68yMzPVtWtXzZkzx9NlAQCAcoRQCgAAoBz48ssvnZ77+vpq9uzZmj17tmcKAgAA5R533wMAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlSnQoNWXKFNlsNqdHgwYNHPPPnTunESNGqFq1aqpcubL69u2rY8eOebBiAAAAAAAAuKJEh1KSdOONN+ro0aOOx6ZNmxzzxo4dq//+979aunSpNmzYoCNHjqhPnz4erBYAAAAAAACuqOjpAgpSsWJFRURE5Jh++vRpzZ8/Xx988IFuv/12SdKCBQsUGxurb7/9VrfccovVpQIAAAAAAMBFJf5MqYSEBEVGRuq6667TwIEDlZSUJEnatm2bLly4oC5dujjaNmjQQFFRUdq8eXO+y8zMzFRqaqrTAwAAAAAAANYp0aFU69attXDhQq1atUpz585VYmKi2rVrpzNnzig5OVne3t4KDg52ek14eLiSk5PzXW5cXJyCgoIcj9q1axfjuwAAAAAAAMDVSvTle927d3f83KRJE7Vu3Vp16tTRhx9+KD8/vyIvd8KECRo3bpzjeWpqKsEUAAAAAACAhUp0KHW14OBgXX/99Tpw4IDuuOMOnT9/XikpKU5nSx07dizXMaiu5OPjIx8fn2KuFshffHx8gW1CQ0MVFRVlQTUAAAAAAFirVIVSaWlpOnjwoB588EG1aNFClSpV0tq1a9W3b19J0v79+5WUlKQ2bdp4uFIgb2fsx2Tz8tKgQYMKbOvn76998fEEUwAAAACAMqdEh1J//vOf1atXL9WpU0dHjhzR5MmTVaFCBQ0YMEBBQUEaOnSoxo0bp5CQEAUGBurJJ59UmzZtuPMeSrSMM6kyWVnqN32uwqJj8mx3PDFBH058XHa7nVAKAAAAAFDmlOhQ6tdff9WAAQN08uRJVa9eXW3bttW3336r6tWrS5L+/ve/y8vLS3379lVmZqa6du2qOXPmeLhqwDVh0TGqGdvU02UAAAAAAOARJTqUWrJkSb7zfX19NXv2bM2ePduiigAAAAAAAOAOXp4uAAAAAAAAAOUPoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHIVPV0AAAAAAJRESUlJstvt+baJj4+3qBogb67sq6GhoYqKirKoIsA1hFIAAAAAcJWkpCTFNmig9IwMT5cC5MvVfdXfz0/x+/YRTKFEIZQCAAAAgKvY7XalZ2RoYZ/uig0NybPdyoRETVn/jYWVAc5c2Vfj7ac0ZNlK2e12QimUKIRSAAAAAJCH2NAQNY8Mz3P+PvspC6sB8lbQvgqURAx0DgAAAAAAAMsRSgEAAAAAAMByhFIAAAAAAACwHKEUAAAAAAAALEcoBQAAAAAAAMsRSgEAAAAAAMByhFIAAAAAAACwHKEUAAAAAAAALEcoBQAAAAAAAMsRSgEAAAAAAMByhFIAAAAAAACwHKEUAAAAAAAALEcoBQAAAAAAAMsRSgEAAAAAAMByFT1dAID8xcfH5zs/MzNTPj4+BS4nNDRUUVFR7ioLAAAAAIBrQigFlFBn7Mdk8/LSoEGD8m1n8/KSycoqcHl+/v7aFx9PMAUAAAAAKBEIpYASKuNMqkxWlvpNn6uw6Jhc2+z/eq1Wz4nLt40kHU9M0IcTH5fdbieUAgAAAACUCIRSQAkXFh2jmrFNc513PDGhwDYAAAAAAJREDHQOAAAAAAAAy3GmFAAAAIAyIykpSXa7vcB23AQGpUVBNz4qaD5QkhFKAQAAACgTkpKSFNuggdIzMgps6+/np/h9+wimUGIlp52Vl81W4I2PgNKMUAoAAABAmWC325WekaGFfborNjQkz3bx9lMasmwlN4FBiZZyLlNZxhS4P69MSNSU9d9YWBngPoRSAAAAAMqU2NAQNY8M93QZgFsUtD/vs5+ysBrAvQilAAAAAJQKBY0Xxdg6QP5c+RthvDVYiVAKAAAAQIlXmPGiADgrzPhUjLcGKxFKAQAAACjxXBkvirF1gNy5Oj4V463BaoRSAAAAAEqN/MbXYWwdIH+Mt4aShlAKAACgjImLi9OyZcu0b98++fn56dZbb9WMGTN0ww03ONqcO3dOTz31lJYsWaLMzEx17dpVc+bMUXg4/6zAegWNFSUxXhQAlEWEUgAAAGXMhg0bNGLECN188826ePGi/vKXv+jOO+/U3r17FRAQIEkaO3asPvvsMy1dulRBQUEaOXKk+vTpo6+//trD1aO8YawoACi/CKUAAADKmFWrVjk9X7hwocLCwrRt2za1b99ep0+f1vz58/XBBx/o9ttvlyQtWLBAsbGx+vbbb3XLLbd4omyUU66MFSUxXhQAlEWEUgAAAGXc6dOnJUkhIZf/4d+2bZsuXLigLl26ONo0aNBAUVFR2rx5M6EUPKKgsW4YLwoAyh5CKQAAgDIsKytLY8aM0W233aZGjRpJkpKTk+Xt7a3g4GCntuHh4UpOTs51OZmZmcrMzHQ8T01NLbaaAQBA+eDl6QIAAABQfEaMGKHdu3dryZIl17ScuLg4BQUFOR61a9d2U4UAAKC8IpQCAAAoo0aOHKkVK1Zo/fr1qlWrlmN6RESEzp8/r5SUFKf2x44dU0RERK7LmjBhgk6fPu14/PLLL8VZOgAAKAcIpQAAAMoYY4xGjhypjz/+WOvWrVN0dLTT/BYtWqhSpUpau3atY9r+/fuVlJSkNm3a5LpMHx8fBQYGOj0AAACuBWNKAQAAlDEjRozQBx98oE8++URVqlRxjBMVFBQkPz8/BQUFaejQoRo3bpxCQkIUGBioJ598Um3atGGQcwAAYBlCKQAAgDJm7ty5kqSOHTs6TV+wYIGGDBkiSfr73/8uLy8v9e3bV5mZmeratavmzJljcaUAAKA8I5QCAAAoY4wxBbbx9fXV7NmzNXv2bAsqAgAAyIkxpQAAAAAAAGA5zpQCAAAAUC7Fx8cXaR4AwD1KdCgVFxenZcuWad++ffLz89Ott96qGTNm6IYbbnC06dixozZs2OD0uuHDh2vevHlWlwsAAACgFEhOOysvm02DBg3ydCkAUK6V6FBqw4YNGjFihG6++WZdvHhRf/nLX3TnnXdq7969CggIcLR79NFHNW3aNMdzf39/T5QLAAAAoBRIOZepLGO0sE93xYaG5NpmZUKipqz/xuLKAKB8KdGh1KpVq5yeL1y4UGFhYdq2bZvat2/vmO7v76+IiAirywMAAABQisWGhqh5ZHiu8/bZT1lcDQCUPyU6lLra6dOnJUkhIc7fZixevFjvv/++IiIi1KtXL02aNCnfs6UyMzOVmZnpeJ6amlo8BQMlTEFjI4SGhioqKqrA5SQlJclut7tlWQAAAACA8qnUhFJZWVkaM2aMbrvtNjVq1Mgx/YEHHlCdOnUUGRmpXbt2afz48dq/f7+WLVuW57Li4uI0depUK8oGSoQz9mOyeXkVOG6Cn7+/9sXH5xsmJSUlqUFsrDLS0695WQAAAACA8qvUhFIjRozQ7t27tWnTJqfpw4YNc/zcuHFj1ahRQ507d9bBgwdVr169XJc1YcIEjRs3zvE8NTVVtWvXLp7CgRIg40yqTFaW+k2fq7DomFzbHE9M0IcTH5fdbs83SLLb7cpIT3fLsgAAAAAA5VepCKVGjhypFStWaOPGjapVq1a+bVu3bi1JOnDgQJ6hlI+Pj3x8fNxeJ1DShUXHqGZs0xK3LAAAAABA+VOiQyljjJ588kl9/PHH+vLLLxUdHV3ga3bu3ClJqlGjRjFXBwAAAAAAgKIq0aHUiBEj9MEHH+iTTz5RlSpVlJycLEkKCgqSn5+fDh48qA8++EA9evRQtWrVtGvXLo0dO1bt27dXkyZNPFw9AAAAAAAA8lKiQ6m5c+dKkjp27Og0fcGCBRoyZIi8vb21Zs0azZw5U2fPnlXt2rXVt29fTZw40QPVAgAAAAAAwFUlOpQyxuQ7v3bt2tqwYYNF1QAAAAAAAMBdvDxdAAAAAAAAAMofQikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUqeroAAAAAAABQcsTHx+c7PzMzUz4+PgUux5V2oaGhioqKKlR9KDsIpQAAAAAAgJLTzsrLZtOgQYPybedlsynLmAKX50o7fz8/xe/bRzBVThFKAQAAAAAApZzLVJYxWtinu2JDQ3JtszIhUVPWf5NvG1fbxdtPaciylbLb7YRS5RShFAAAAAAAcIgNDVHzyPBc5+2znyqwTWHaoXxjoHMAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5BjoHUGzi4+MLbBMaGsqdNgAAAACgHCKUAuB2Z+zHZPPy0qBBgwps6+fvr33x8QRTAAAAAFDOEEoBcLuMM6kyWVnqN32uwqJj8mx3PDFBH058XHa7nVAKAAAAAMoZQikAxSYsOkY1Y5t6ugwAAAAAQAnEQOcAAAAAAACwHKEUAAAAAAAALEcoBQAAAAAAAMsRSgEAAAAAAMByDHReyiQlJclut+fbJj4+3qJqUBYVtP+wfwEAAAAA3IFQqhRJSkpSg9hYZaSne7oUlEFn7Mdk8/LSoEGDPF0KAAAAAKAcIJQqRex2uzLS09Vv+lyFRcfk2W7/12u1ek6chZWhLMg4kyqTlcX+BQAAAACwBKFUKRQWHaOasU3znH88McHCalDWsH8BAAAAAKzAQOcAAAAAAACwHGdKlSAFDWLOANMoqwrat0NDQxUVFVXgcly5EYCrywIAAAAAFC9CqRKCQcxRHrk6uLqfv7/2xcfnGya5+jfkyrIAAAAAAMWPUKqEcGUQcwaYRlnjyuDqxxMT9OHEx2W32/MNklz5G3J1WQAAAACs48pVQVzxUDYRSpUw+Q0yzQDTKKsKGlzdU8sCAAAAUHyS087Ky2Yr8MoJSfL381P8vn0EU2UMoRQAAAAAALBcyrlMZRmjhX26KzY0JM928fZTGrJsJVc8lEGEUgAAAAAAwGNiQ0PUPDLc02XAAwilAJQ7XLMOAAAAAJ5HKAWg3HD1bn8Sd+kDAAAAgOJGKAWg3HDlbn8Sd+kDAAAAACsQSgEod7hDHwAAAAB4HqEUAAAAACdJSUmy2+35tnF1/MWCluXKWI8AIBV8vGBc2NKHUAoAAACAQ1JSkmIbNFB6Rka+7fz9/BS/b1++/wC6uiwAyE9y2ll52WwFjg3rynEJJQuhFAAAAAAHu92u9IwMLezTXbGhIbm2ibef0pBlKwscf9GVZa1MSNSU9d+4pXYAZVPKuUxlGeOW4xJKFkIpAAAAADnEhoaoeWR4sS9rn/2UW9YBoOxz53EJJQOhFAAAAFAGuHMcKAAorVwZp45jYclBKAUAAACUcu4cBwoASiNXx52SOBaWJIRSFnDlWyvuOgKUPNzdAwBQWrhzHCgAKI1cGXdK4lhY0hBKFbOkpCQ1iI1VRnq6p0sB4KIz9mOyeXkV+C2Ln7+/9sXH82EGACgxGG8FQHnHcbB0IZQqZna7XRnp6eo3fa7ComPybLf/67VaPSfOwsoA5CXjTKpMVla+f7fHExP04cTH+YYFAFDs3H3WfUFtOYMfAGAVQimLhEXHqGZs0zznH09MsLAaoPTxRAe6oL9bV9ebmZkpHx+fa24jcckgAJQ3ro4V5YrCjLcCAIAVCKUAlGiuXkpntcLUZfPyksnKuuY2EpcMAkB548pYUZK0MiFRU9Z/k++yXB1vxZVlAQDgDoRSAEo0Vy6lk6y/BLawdeXXzpU2EpcMAkB5VtAYKfvspzyyLAAArgWhFIBSoaReAutqXfm1c6UNAJRHroylVNovfy7oPTK+EwB4hiufQVLJHarDlfpLwmcjoRQAAABKHFfHUvKy2ZRlTIHL8/fzU/y+fR7vfF/JneNFAQDcpzDHZ1c+h6z+rHK1/pLw2UgoBQClTEHfmpeEbzyKW0n95qek1lWaufotJdu17HFlLKXssY8KGiMp3n5KQ5atLHGXPxfmPQIArFPY8fxK2meVK/WXlM9GQikAKCVcHVy9rA+GnpSUpAaxscpIT8+3ndXboaTWVZq5uk0ltmtZlt/4R9ljHxU0RlJJ58p7BABYz9Ux+ErqZ1Vp+HwsM6HU7Nmz9fLLLys5OVlNmzbVrFmz1KpVK0+XBQBu48rg6uVhMHS73a6M9PQStx1Kal2lmSvbVGK7Xqvy1IfiTFP3K2ibMiYWgJIqv+MTxy7rlIlQ6t///rfGjRunefPmqXXr1po5c6a6du2q/fv3KywszNPlAYBbuTIguisfpO4alNHVf+LcfWmbuwaGL6l14Q9s0+JTXvpQyWln5WWzFXimaUkYW6O0cHWbAkBJw/GrZCkTodRrr72mRx99VA8//LAkad68efrss8/07rvv6tlnn/VwdQBgHVcv8ZMkm5eXTFbWNbdx5bKpknppW0mtC7BKeelDpZzLVJYxpWJsjdLClW0qMSYWgJLHleMXxy7rlPpQ6vz589q2bZsmTJjgmObl5aUuXbpo8+bNHqwMAKznyiV+krT/67VaPScu33autHH1sqmSemlbSa0LsEJ57EOVhrE1ShtXx1sBgJKG8fxKhlIfStntdl26dEnh4c47U3h4uPbt25frazIzM5WZmel4fvr0aUlSamqq2+tLS0uTJP0Wv0vn08/m2e7EoYQC27nShmWxLJbFsiTpwrmMfJd18Xxmge1caXPh3OXbzG7bts1xvMvN/v373b6sfLfD4YOlui7pcjiQVcBZaq60Kc3LcmWbSn9s17S0tGL5LM9epnHhVs6lSWH7UFb2n6Q/+lDbjx5T2vkLubaJP3GywDautvvp5OV/QKz8+8zex616jyyLZbGs4l9Waa6dZXl2Wa5+Drnr8yV7fR7vP5lS7rfffjOSzDfffOM0/emnnzatWrXK9TWTJ082knjw4MGDBw8ePFx+/PLLL1Z0bSxT2D4U/ScePHjw4MGDR2EfBfWfSv2ZUqGhoapQoYKOHTvmNP3YsWOKiIjI9TUTJkzQuHHjHM9TUlJUp04dJSUlKSgoqFjrLclSU1NVu3Zt/fLLLwoMDPR0OR7DdriM7XAZ2+EytsNlbIfLytt2MMbozJkzioyM9HQpblXYPtTV/aesrCydOnVK1apVk81mK/Z6s5W3/c8d2GaFxzYrPLZZ0bDdCo9tVnie2Gau9p9KfSjl7e2tFi1aaO3aterdu7eky52ktWvXauTIkbm+xsfHJ9e7SQUFBbFTSwoMDGQ7iO2Qje1wGdvhMrbDZWyHy8rTdiiLX1oVtg+VW/8pODjYgkpzV572P3dhmxUe26zw2GZFw3YrPLZZ4Vm9zVzpP5X6UEqSxo0bp8GDB6tly5Zq1aqVZs6cqbNnzzruJAMAAICc6EMBAABPKhOh1P33368TJ07oueeeU3Jyspo1a6ZVq1blGLgTAAAAf6APBQAAPKlMhFKSNHLkyDwv1yuIj4+PJk+enOslfeUJ2+EytsNlbIfL2A6XsR0uYztcxnYoW66lD+UJ7H+FxzYrPLZZ4bHNiobtVnhss8IrydvMZkwZu78xAAAAAAAASjwvTxcAAAAAAACA8odQCgAAAAAAAJYjlAIAAAAAAIDlCKUkzZ49W3Xr1pWvr69at26t7777ztMl5Wnjxo3q1auXIiMjZbPZtHz5cqf5xhg999xzqlGjhvz8/NSlSxclJCQ4tTl16pQGDhyowMBABQcHa+jQoUpLS3Nqs2vXLrVr106+vr6qXbu2XnrppRy1LF26VA0aNJCvr68aN26s//3vf4WupSji4uJ08803q0qVKgoLC1Pv3r21f/9+pzbnzp3TiBEjVK1aNVWuXFl9+/bVsWPHnNokJSWpZ8+e8vf3V1hYmJ5++mldvHjRqc2XX36pm266ST4+Pqpfv74WLlyYo56C9h9XaimKuXPnqkmTJgoMDFRgYKDatGmjlStXlqttcLUXX3xRNptNY8aMKdS6y8J2mDJlimw2m9OjQYMG5W47/Pbbbxo0aJCqVasmPz8/NW7cWFu3bnXMLw/HyLp16+bYF2w2m0aMGCGp/OwLKB3c0a+5WkHHw9KuoG22bNky3XnnnapWrZpsNpt27tzp0nILOmaVZsWxzRYuXJhjP/P19S2eN+Ah+W23CxcuaPz48WrcuLECAgIUGRmphx56SEeOHClwuaXpf6/CKo5tVt6PaVOmTFGDBg0UEBCgqlWrqkuXLtqyZUuByy2v+5lUtG3m0f3MlHNLliwx3t7e5t133zV79uwxjz76qAkODjbHjh3zdGm5+t///mf++te/mmXLlhlJ5uOPP3aa/+KLL5qgoCCzfPly88MPP5i7777bREdHm4yMDEebbt26maZNm5pvv/3WfPXVV6Z+/fpmwIABjvmnT5824eHhZuDAgWb37t3mX//6l/Hz8zNvvfWWo83XX39tKlSoYF566SWzd+9eM3HiRFOpUiXz448/FqqWoujatatZsGCB2b17t9m5c6fp0aOHiYqKMmlpaY42jz32mKldu7ZZu3at2bp1q7nlllvMrbfe6ph/8eJF06hRI9OlSxezY8cO87///c+EhoaaCRMmONr8/PPPxt/f34wbN87s3bvXzJo1y1SoUMGsWrXK0caV/aegWorq008/NZ999pn56aefzP79+81f/vIXU6lSJbN79+5ysw2u9N1335m6deuaJk2amNGjR7u87rKyHSZPnmxuvPFGc/ToUcfjxIkT5Wo7nDp1ytSpU8cMGTLEbNmyxfz888/m888/NwcOHHC0KQ/HyOPHjzvtB6tXrzaSzPr1640x5WNfQOnhjn7N1Qo6HpZ2BW2zRYsWmalTp5p33nnHSDI7duwocJmuHLNKs+LYZgsWLDCBgYFO+1lycnLxvAEPyW+7paSkmC5duph///vfZt++fWbz5s2mVatWpkWLFvkus7T971VYxbHNyvsxbfHixWb16tXm4MGDZvfu3Wbo0KEmMDDQHD9+PM9lluf9zJiibTNP7mflPpRq1aqVGTFihOP5pUuXTGRkpImLi/NgVa65egfMysoyERER5uWXX3ZMS0lJMT4+PuZf//qXMcaYvXv3Gknm+++/d7RZuXKlsdls5rfffjPGGDNnzhxTtWpVk5mZ6Wgzfvx4c8MNNzie9+vXz/Ts2dOpntatW5vhw4e7XIu7HD9+3EgyGzZscKynUqVKZunSpY428fHxRpLZvHmzMebyH7KXl5dT52Hu3LkmMDDQ8b6feeYZc+ONNzqt6/777zddu3Z1PC9o/3GlFneqWrWq+cc//lHutsGZM2dMTEyMWb16tenQoYMjlCpP22Hy5MmmadOmuc4rL9th/Pjxpm3btnnOL6/HyNGjR5t69eqZrKyscrMvoHQqSr8mN/kdD8ua3P4ZyZaYmOhywFLQMasscdc2W7BggQkKCnJrbSVZftst23fffWckmcOHD+fZpjT/71VY7tpmHNOcnT592kgya9asybMN+5kzV7aZJ/ezcn353vnz57Vt2zZ16dLFMc3Ly0tdunTR5s2bPVhZ0SQmJio5Odnp/QQFBal169aO97N582YFBwerZcuWjjZdunSRl5eX45S+zZs3q3379vL29na06dq1q/bv36/ff//d0ebK9WS3yV6PK7W4y+nTpyVJISEhkqRt27bpwoULTutu0KCBoqKinLZD48aNFR4e7lR/amqq9uzZ49J7dGX/caUWd7h06ZKWLFmis2fPqk2bNuVuG4wYMUI9e/bMUWt52w4JCQmKjIzUddddp4EDByopKalcbYdPP/1ULVu21H333aewsDA1b95c77zzjmN+eTxGnj9/Xu+//74eeeQR2Wy2crMvoGy4lr+TvI6HyF1Bf9PIXVpamurUqaPatWvrnnvucRwjy6vTp0/LZrMpODg41/ll7X8vdyhom2XjmHbZ+fPn9fbbbysoKEhNmzbNsw372R9c2WbZPLWfletQym6369KlS04db0kKDw9XcnKyh6oquuya83s/ycnJCgsLc5pfsWJFhYSEOLXJbRlXriOvNlfOL6gWd8jKytKYMWN02223qVGjRo51e3t75zi4X11fUd9jamqqMjIyXNp/XKnlWvz444+qXLmyfHx89Nhjj+njjz9Ww4YNy9U2WLJkibZv3664uLgc88rTdmjdurUWLlyoVatWae7cuUpMTFS7du105syZcrMdfv75Z82dO1cxMTH6/PPP9fjjj2vUqFF67733nN5HeTpGLl++XCkpKRoyZIhjveVhX0DZUNS/k/yOh8hdQccs5HTDDTfo3Xff1SeffKL3339fWVlZuvXWW/Xrr796ujSPOHfunMaPH68BAwYoMDAw1zZl7X+va+XKNpM4pknSihUrVLlyZfn6+urvf/+7Vq9erdDQ0Fzbsp9dVphtJnl2P6tY7GsAitGIESO0e/dubdq0ydOleMQNN9ygnTt36vTp0/roo480ePBgbdiwwdNlWeaXX37R6NGjtXr16jI3uGhhde/e3fFzkyZN1Lp1a9WpU0cffvih/Pz8PFiZdbKystSyZUu98MILkqTmzZtr9+7dmjdvngYPHuzh6jxj/vz56t69uyIjIz1dCmCZ/I6HQ4cO9WBlKEvatGmjNm3aOJ7feuutio2N1VtvvaXnn3/eg5VZ78KFC+rXr5+MMZo7d66nyykVCrPNOKZJnTp10s6dO2W32/XOO++oX79+2rJlS44vEvGHwm4zT+5n5fpMqdDQUFWoUCHHnX6OHTumiIgID1VVdNk15/d+IiIidPz4caf5Fy9e1KlTp5za5LaMK9eRV5sr5xdUy7UaOXKkVqxYofXr16tWrVqO6RERETp//rxSUlLyra+o7zEwMFB+fn4u7T+u1HItvL29Vb9+fbVo0UJxcXFq2rSpXn/99XKzDbZt26bjx4/rpptuUsWKFVWxYkVt2LBBb7zxhipWrKjw8PBysR1yExwcrOuvv14HDhwoN/tDjRo11LBhQ6dpsbGxjlOPy9sx8vDhw1qzZo3+7//+zzGtvOwLKBvc9Xdy5fEQuSvomIWCVapUSc2bNy93+1l2uHL48GGtXr063zN+ytr/XkVVmG2Wm/J4TAsICFD9+vV1yy23aP78+apYsaLmz5+fa1v2s8sKs81yY+V+Vq5DKW9vb7Vo0UJr1651TMvKytLatWudvvkoLaKjoxUREeH0flJTU7VlyxbH+2nTpo1SUlK0bds2R5t169YpKytLrVu3drTZuHGjLly44GizevVq3XDDDapataqjzZXryW6TvR5XaikqY4xGjhypjz/+WOvWrVN0dLTT/BYtWqhSpUpO696/f7+SkpKctsOPP/7o9M9n9odC9j+1Bb1HV/YfV2pxp6ysLGVmZpabbdC5c2f9+OOP2rlzp+PRsmVLDRw40PFzedgOuUlLS9PBgwdVo0aNcrM/3Hbbbdq/f7/TtJ9++kl16tSRVH6OkdkWLFigsLAw9ezZ0zGtvOwLKBvc9Xdy5fEQuSvobxoFu3Tpkn788cdytZ9lhysJCQlas2aNqlWrlm/7sva/V1EUdpvlhmPaH//z5Ib9LHf5bbPcWLqfeWR49RJkyZIlxsfHxyxcuNDs3bvXDBs2zAQHB5fYW7qeOXPG7Nixw+zYscNIMq+99prZsWOH444NL774ogkODjaffPKJ2bVrl7nnnntyvd158+bNzZYtW8ymTZtMTEyM0+3OU1JSTHh4uHnwwQfN7t27zZIlS4y/v3+O251XrFjRvPLKKyY+Pt5Mnjw519udF1RLUTz++OMmKCjIfPnll063rExPT3e0eeyxx0xUVJRZt26d2bp1q2nTpo1p06aNY372Lc/vvPNOs3PnTrNq1SpTvXr1XG95/vTTT5v4+Hgze/bsXG95XtD+U1AtRfXss8+aDRs2mMTERLNr1y7z7LPPGpvNZr744otysw1yc+Xd98rTdnjqqafMl19+aRITE83XX39tunTpYkJDQx23fi0P2+G7774zFStWNH/7299MQkKCWbx4sfH39zfvv/++o015OEYac/kuM1FRUWb8+PE55pWHfQGlhzv6NbfffruZNWuW43lBx8PSrqBtdvLkSbNjxw7z2WefGUlmyZIlZseOHebo0aOOZTz44IPm2WefdTx35ZhVmhXHNps6dar5/PPPzcGDB822bdtM//79ja+vr9mzZ4/l76+45Lfdzp8/b+6++25Tq1Yts3PnTqc++ZV3p73677O0/e9VWMWxzcrzMS0tLc1MmDDBbN682Rw6dMhs3brVPPzww8bHx8fs3r3bsQz2s2vfZp7cz8p9KGWMMbNmzTJRUVHG29vbtGrVynz77beeLilP69evN5JyPAYPHmyMuXz75EmTJpnw8HDj4+NjOnfubPbv3++0jJMnT5oBAwaYypUrm8DAQPPwww+bM2fOOLX54YcfTNu2bY2Pj4+pWbOmefHFF3PU8uGHH5rrr7/eeHt7mxtvvNF89tlnTvNdqaUocnv/ksyCBQscbTIyMswTTzxhqlatavz9/c29997r1LEwxphDhw6Z7t27Gz8/PxMaGmqeeuopc+HCBac269evN82aNTPe3t7muuuuc1pHtoL2H1dqKYpHHnnE1KlTx3h7e5vq1aubzp07OwKp8rINcnN1KFVetsP9999vatSoYby9vU3NmjXN/fffbw4cOFDutsN///tf06hRI+Pj42MaNGhg3n77baf55eEYaYwxn3/+uZGU6/LKy76A0sEd/Zo6deqYyZMnO54XdDws7QraZgsWLMh1/pXbqEOHDo722Qo6ZpVmxbHNxowZ4zi+hYeHmx49epjt27db+8aKWX7bLTExMc8++fr16x3LuPrv05jS9b9XYRXHNivPx7SMjAxz7733msjISOPt7W1q1Khh7r77bvPdd985LYP97Nq3mSf3M5sxxhThBCsAAAAAAACgyMr1mFIAAAAAAADwDEIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAlGkLFy5UcHBwsa/n0KFDstls2rlzZ7GvCwAAoKj279+viIgInTlzxq3LtdlsWr58uVuXmZuOHTtqzJgxblte//799eqrr7pteQAKh1AKQIl24sQJPf7444qKipKPj48iIiLUtWtXff3118W2zrp168pms8lmsykgIEA33XSTli5dmu9rateuraNHj6pRo0bFVhcAACjbhgwZot69exfrOiZMmKAnn3xSVapUcUx755131LRpU1WuXFnBwcFq3ry54uLiirWOKVOmOPpbFStWVN26dTV27FilpaXl+7ply5bp+eefd1sdEydO1N/+9jedPn3abcsE4DpCKQAlWt++fbVjxw699957+umnn/Tpp5+qY8eOOnnyZLGud9q0aTp69Kh27Nihm2++Wffff7+++eabXNueP39eFSpUUEREhCpWrFisdQEAABRVUlKSVqxYoSH/r717D4qyeuMA/g1ZrruggAqCIokgCm1ArpKDpIIgaTRqlMPImgumVOLYqNGEDOAlmoQJRTMhIKRUMnF1mlBDaWUkwYAQEZOLeRub8IrFRTi/PxzfaeVSY4T46/uZ2Rn2nPOe93lf/nnmec97dtEiqe2zzz7DihUrsHz5clRUVKC4uBirV6/+y+JQX5gwYQKuXr2KxsZGJCUl4dNPP8U777zT7di2tjYAgJWVlV5B7Z9yd3fHmDFjsHPnzj6bk4j+PhaliGjAunnzJnQ6HZKSkjBt2jQ4OjpCpVIhJiYGL730EgAgOTkZHh4eMDc3x8iRIxEVFfWXSdT+/fvh5eUFExMTPP3004iPj8e9e/f0xigUCtja2sLFxQVpaWkwNTXFgQMHANxfSZWYmIjw8HBYWFhgyZIl3b6+V11djdmzZ8PCwgIKhQK+vr6oq6uT+tPT0+Hm5gYTExOMGzcOW7du7aM7R0RERP9vioqKoFKpYGxsDDs7O7z77rt6+cudO3cQFhYGc3Nz2NnZISUlpcurbnv27IFSqYS9vb3UptVqERoaCo1GA2dnZ0yYMAELFizA+vXrpTGlpaUICAiAjY0NLC0t4efnhx9//LHXeC9evIjQ0FAMHjwYVlZWCAkJQWNjo94YQ0ND2NrawsHBAa+++irCwsKg1WoB3F9J9eyzzyI9PR1OTk4wMTEB0PX1vdbWVqxZswYjR46EsbExnJ2dkZGRIfWfPn0as2bNglwux/Dhw7Fw4UL89ttvenHMmTMHu3bt6v0fQET/ChaliGjAksvlkMvlyM/PR2tra7djDAwMkJqaiurqamRnZ6OwsBCrV6/ucU6dTofw8HBER0fjzJkz2L59O7KysvQSr4cZGhpCJpNJT+gA4KOPPoJSqUR5eTliY2O7HHP58mVMnToVxsbGKCwsxKlTp7B48WIpeczNzcXatWuxfv161NTUYMOGDYiNjUV2dvbfvT1ERET0H3H58mUEBwdj4sSJqKysxLZt25CRkYF169ZJY1auXIni4mJotVocPnwYOp2uS+FIp9Phueee02uztbVFSUkJLly40OP579y5A7VajePHj6OkpARjx45FcHBwj/tStbe3IzAwEAqFAjqdDsXFxZDL5QgKCtLLpx5mamqq13/+/Hns3bsXX3/9dY/7doaHh+PLL79EamoqampqsH37dsjlcgD3H3BOnz4dnp6eKCsrw7fffotr164hNDRUbw6VSoWTJ0/2mG8S0b9IEBENYF999ZUYMmSIMDExEc8//7yIiYkRlZWVPY7Py8sT1tbW0vfMzExhaWkpfZ8xY4bYsGGD3jE5OTnCzs5O+u7o6ChSUlKEEEK0traKDRs2CADi4MGDUv/LL7+sN0dDQ4MAIMrLy4UQQsTExAgnJyfR1tbWbZxjxowRX3zxhV5bYmKi8PHx6fHaiIiI6P+bWq0WISEhXdrfe+894erqKjo7O6W2tLQ0IZfLRUdHh7h9+7aQyWQiLy9P6r9586YwMzMT0dHRUptSqRQJCQl6c1+5ckVMnjxZABAuLi5CrVaL3bt3i46Ojh7j7OjoEAqFQhw4cEBqAyD27dsnhLifWz0cb2trqzA1NRUFBQVCCCHi4uKEUqmU+svKyoSNjY2YP3++1C+TycSvv/6qd24/Pz/pmmprawUAcfjw4W7jTExMFDNnztRru3jxogAgamtrpbbKykoBQDQ2NvZ4zUT07+BKKSIa0ObNm4crV65Aq9UiKCgIx44dg5eXF7KysgAAR44cwYwZM2Bvbw+FQoGFCxeiqakJv//+e7fzVVZWIiEhQVqFJZfLERkZiatXr+ods2bNGsjlcpiZmSEpKQkffPABXnzxRan/4aeMD6uoqICvry9kMlmXvrt376Kurg4ajUYvjnXr1um93kdEREQEADU1NfDx8cFTTz0ltU2ZMgXNzc24dOkS6uvr0d7eDpVKJfVbWlrC1dVVb54//vhDeg3uATs7O5w4cQJVVVWIjo7GvXv3oFarERQUhM7OTgDAtWvXEBkZibFjx8LS0hIWFhZobm7GL7/80m28lZWVOH/+PBQKhZTnWFlZoaWlRS/Xqaqqglwuh6mpKVQqFXx8fLBlyxap39HREUOHDu3xvlRUVGDQoEHw8/PrMY6jR4/q5Vvjxo0DAL04TE1NAaDH/JGI/j3ckZeIBjwTExMEBAQgICAAsbGxiIiIQFxcHF544QXMnj0by5Ytw/r162FlZYXjx49Do9Ggra0NZmZmXeZqbm5GfHw85s6d2+15Hli1ahUWLVok7T/w5yQQAMzNzXuN+UFy050He17t2LEDkyZN0usbNGhQr/MSERERPSobGxvcuHGj2z53d3e4u7sjKioKS5cuha+vL4qKijBt2jSo1Wo0NTXh448/hqOjI4yNjeHj49Pjq3jNzc3w9vZGbm5ul74/F5lcXV2h1WphaGiIESNGwMjISG/sP8m3HsQxZ84cJCUldemzs7OT/r5+/XqX2Iiof7AoRURPnPHjxyM/Px+nTp1CZ2cnNm3aBAOD+ws/9+zZ0+uxXl5eqK2thbOzc6/jbGxs/nJMb5555hlkZ2ejvb29y2qp4cOHY8SIEaivr0dYWNgjn4OIiIj+G9zc3LB3714IIaQHZcXFxVAoFHBwcMCQIUMgk8lQWlqKUaNGAQBu3bqFc+fOYerUqdI8np6eOHPmzF+eb/z48QDur+5+cK6tW7ciODgYwP1NzB/eLPzPvLy8sHv3bgwbNgwWFhY9jjMyMvpH+ZaHhwc6OztRVFQEf3//buPYu3cvRo8e3esvJJ8+fRoODg6wsbF55FiI6NHw9T0iGrCampowffp07Ny5Ez/99BMaGhqQl5eHDz/8ECEhIXB2dkZ7ezs2b96M+vp65OTk4JNPPul1zrVr1+Lzzz9HfHw8qqurUVNTg127duH999/v09jfeust3L59G6+99hrKysrw888/IycnB7W1tQCA+Ph4bNy4EampqTh37hyqqqqQmZmJ5OTkPo2DiIiIniy3bt1CRUWF3mfJkiW4ePEi3n77bZw9exb79+9HXFwcVq5cCQMDAygUCqjVaqxatQpHjx5FdXU1NBoNDAwM9FZ7BwYG4sSJE+jo6JDali1bhsTERBQXF+PChQsoKSlBeHg4hg4dCh8fHwDA2LFjkZOTg5qaGvzwww8ICwvrdZVSWFgYbGxsEBISAp1Oh4aGBhw7dgzLly/HpUuX+uxejR49Gmq1GosXL0Z+fr50ngcPKd98801cv34dCxYsQGlpKerq6lBQUIDXX39d7x7odDrMnDmzz+Iior+PRSkiGrDkcjkmTZqElJQUTJ06Fe7u7oiNjUVkZCS2bNkCpVKJ5ORkJCUlwd3dHbm5udi4cWOvcwYGBuLgwYM4dOgQJk6ciMmTJyMlJQWOjo59Gru1tTUKCwvR3NwMPz8/eHt7Y8eOHdKqqYiICKSnpyMzMxMeHh7w8/NDVlYWnJyc+jQOIiIierIcO3YMnp6eep/ExER88803OHnyJJRKJZYuXQqNRqP3UC05ORk+Pj6YPXs2/P39MWXKFLi5ueltTzBr1iwYGhriyJEjUpu/vz9KSkrwyiuvwMXFBfPmzYOJiQm+++47WFtbAwAyMjJw48YNeHl5YeHChVi+fDmGDRvW4zWYmZnh+++/x6hRozB37ly4ublBo9GgpaWl15VTj2Lbtm2YP38+oqKiMG7cOERGRkorvEaMGIHi4mJ0dHRg5syZ8PDwwIoVKzB48GBplX1LSwvy8/MRGRnZp3ER0d/zlBBCPO4giIiIiIiIqO/cvXsX9vb22LRpEzQajdSelpYGrVaLgoKCxxjdwLFt2zbs27cPhw4detyhEP0ncU8pIiIiIiKiJ1x5eTnOnj0LlUqFW7duISEhAQAQEhKiN+6NN97AzZs3cefOHSgUiscR6oAik8mwefPmxx0G0X8WV0oRERERERE94crLyxEREYHa2loYGRnB29sbycnJ8PDweNyhERH1iEUpIiIiIiIiIiLqd9zonIiIiIiIiIiI+h2LUkRERERERERE1O9YlCIiIiIiIiIion7HohQREREREREREfU7FqWIiIiIiIiIiKjfsShFRERERERERET9jkUpIiIiIiIiIiLqdyxKERERERERERFRv2NRioiIiIiIiIiI+t3/ALic4WK/tiM9AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot original distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(y, bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Original SalePrice Distribution')\n",
    "plt.xlabel('SalePrice')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Plot log-transformed distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(y_log, bins=50, color='salmon', edgecolor='black')\n",
    "plt.title('Log-Transformed SalePrice Distribution')\n",
    "plt.xlabel('Log(SalePrice)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Outlier Removal: 1460 rows\n",
      "After Outlier Removal: 1432 rows\n",
      "Cross-Validation Scores: [-0.01714227 -0.0179534  -0.02560619 -0.01922953 -0.0177627 ]\n",
      "Mean CV Score: -0.019538819086753798\n",
      "RMSE: 0.12786756064088864\n",
      "MAPE: 9.060036024442187%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "# Load the train dataset\n",
    "file_path = '../data/housing_prices_data/train.csv'\n",
    "train_data = pd.read_csv(file_path, index_col=\"Id\")\n",
    "\n",
    "# Columns to be deleted\n",
    "columns_to_delete = ['MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']\n",
    "\n",
    "# Delete the specified columns\n",
    "train_data_cleaned = train_data.drop(columns=columns_to_delete, axis=1)\n",
    "\n",
    "# Define the input features (X) and the output (y)\n",
    "X = train_data_cleaned.drop('SalePrice', axis=1)\n",
    "y = train_data_cleaned['SalePrice']\n",
    "\n",
    "# Feature engineering: Apply log transformation to target variable\n",
    "y = np.log1p(y)\n",
    "\n",
    "# Identify the categorical columns in X\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Initialize a LabelEncoder for each categorical column\n",
    "label_encoders = {column: LabelEncoder() for column in categorical_columns}\n",
    "\n",
    "# Apply Label Encoding to each categorical column\n",
    "for column in categorical_columns:\n",
    "    X[column] = label_encoders[column].fit_transform(X[column])\n",
    "\n",
    "print(f\"Before Outlier Removal: {X.shape[0]} rows\")\n",
    "\n",
    "# Calculate IQR for target variable (y)\n",
    "Q1_y = y.quantile(0.25)\n",
    "Q3_y = y.quantile(0.75)\n",
    "IQR_y = Q3_y - Q1_y\n",
    "\n",
    "# Identify outliers in y and remove them\n",
    "y_cleaned = y[(y >= (Q1_y - 1.5 * IQR_y)) & (y <= (Q3_y + 1.5 * IQR_y))]W\n",
    "\n",
    "# Apply the same outlier removal to X\n",
    "X_cleaned = X.loc[y_cleaned.index]\n",
    "\n",
    "# Print the number of rows after outlier removal\n",
    "print(f\"After Outlier Removal: {y_cleaned.shape[0]} rows\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_cleaned, y_cleaned, test_size=0.30, random_state=42)\n",
    "\n",
    "# Fill NaN values in X_train and X_val with the median of the respective columns\n",
    "X_train_filled = X_train.fillna(X_train.median())\n",
    "X_val_filled = X_val.fillna(X_val.median())\n",
    "\n",
    "# Create a Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Cross-validation score (5-fold cross-validation)\n",
    "cv_score = cross_val_score(rf_model, X_train_filled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(f\"Cross-Validation Scores: {cv_score}\")\n",
    "print(f\"Mean CV Score: {cv_score.mean()}\")\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_model.fit(X_train_filled, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_val_pred_filled = rf_model.predict(X_val_filled)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_filled = sqrt(mean_squared_error(y_val, y_val_pred_filled))\n",
    "\n",
    "# Calculate MAPE (mean absolute percentage error) on original scale\n",
    "mape = np.mean(np.abs((np.expm1(y_val) - np.expm1(y_val_pred_filled)) / np.expm1(y_val))) * 100\n",
    "\n",
    "# Print the RMSE, MAPE, and Cross-Validation Score\n",
    "print(f\"RMSE: {rmse_filled}\")\n",
    "print(f\"MAPE: {mape}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
